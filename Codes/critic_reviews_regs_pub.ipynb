{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMLAgtIrAeuq8ZVJ1F5lKzm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahyarhabibi/GenderGaps_Hollywood/blob/main/Codes/critic_reviews_regs_pub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook generates the results used to estimate the regression model specified in Equation 3."
      ],
      "metadata": {
        "id": "y5oDTUAkZ7J-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GelXYJw-TpL4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import scipy as sc\n",
        "import statsmodels.api as sm\n",
        "from patsy import dmatrices\n",
        "from statsmodels.iolib.summary2 import summary_col\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "B4bUU9grQ9_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOwpdY-8W0X1",
        "outputId": "0dd3755b-51f9-4777-e0e9-c15540d7443a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sl52CKHD2kg"
      },
      "outputs": [],
      "source": [
        "# Directories to read data and store results\n",
        "#Please add the parent folder to your Google Drive\n",
        "# Public Link: https://drive.google.com/drive/folders/1TYCDAJOCiLZw4TObcLac5GnL5YtwYnUD?usp=sharing\n",
        "parent_dir = \"/content/gdrive/MyDrive/GenderGaps_Hollywood/\" # You may need to change the address\n",
        "data_dir = os.path.join(parent_dir, 'Data/')\n",
        "results_dir = os.path.join(parent_dir,'Results/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Movies data\n",
        "df_movies = pd.read_pickle(data_dir + 'movies_info_merged_MIW_pkl.zip')\n",
        "\n",
        "# Reviews data\n",
        "df_crevs = pd.read_pickle(data_dir + 'reviews_critics_merged.zip')\n",
        "crev_cols = ['Title', 'Year', 'title_year' ,'source', 'author', 'score','C_count', \n",
        "             'R_count', 'C_Female', 'C_start', 'C_end', 'C_avg','C_exper']\n",
        "df_crevs = df_crevs[crev_cols]"
      ],
      "metadata": {
        "id": "x_3sNf1ZW2hX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a list of genres\n",
        "genres = set(df_movies['genre'].sum())\n",
        "for gen in genres:\n",
        "    df_movies[gen] = df_movies['genre'].map(lambda x: 1 if gen in x else 0)\n",
        "    \n",
        "df_movies = df_movies.rename(columns={'Film-Noir': 'FilmNoir', 'Sci-Fi': \n",
        "                                      'SciFi', 'Reality-TV': 'RealityTV',\n",
        "                                      'Talk-Show': 'TalkShow'})\n",
        "\n",
        "genres = genres - {'Film-Noir','Sci-Fi','Reality-TV', 'Talk-Show'}\n",
        "genres = list(genres.union({'FilmNoir','SciFi','RealityTV', 'TalkShow'}))"
      ],
      "metadata": {
        "id": "Pt4Fil6FXqZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plots' embedding vectors data\n",
        "plot_vectors = [f'plot_vec{i}' for i in range(100)]\n",
        "X_vecs = df_movies[plot_vectors]"
      ],
      "metadata": {
        "id": "h80FTw4xhIKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cast data\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "\n",
        "X_cast = pd.DataFrame(mlb.fit_transform(df_movies['cast']),columns=mlb.classes_, index=df_movies.index)\n",
        "\n",
        "# Keeping actors whose names showed up at least 5 times\n",
        "X_cast = X_cast[X_cast.columns[X_cast.sum()>=10]]"
      ],
      "metadata": {
        "id": "xFtbn9X2msAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Companies with at least 10 movies\n",
        "X_company = pd.get_dummies(df_movies['company'])\n",
        "X_company = X_company[X_company.columns[X_company.sum()>=10]]\n",
        "\n",
        "# Distributors with at least 10 movies\n",
        "X_dist = pd.get_dummies(df_movies['Distributor'])\n",
        "X_dist = X_dist[X_dist.columns[X_dist.sum()>=10]]"
      ],
      "metadata": {
        "id": "6OCK5tWNmsAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Countries\n",
        "df_movies['country_list'] = df_movies['country'].map(lambda x: re.sub(' ','',x)).\\\n",
        "                        map(lambda x: x.split(','))\n",
        "\n",
        "X_country = pd.DataFrame(mlb.fit_transform(df_movies['country_list']),\n",
        "             columns=mlb.classes_, index=df_movies.index)\n",
        "\n",
        "X_country = X_country[X_country.columns[X_country.sum()>=10]]\n",
        "\n",
        "#Language\n",
        "df_movies['lang_list'] = df_movies['language'].map(lambda x: re.sub(' ','',x)).\\\n",
        "                        map(lambda x: x.split(','))\n",
        "X_lang = pd.DataFrame(mlb.fit_transform(df_movies['lang_list']),\n",
        "             columns=mlb.classes_, index=df_movies.index)\n",
        "X_lang = X_lang[X_lang.columns[X_lang.sum()>=10]]\n",
        "\n",
        "# Age ratings Text\n",
        "vector_rating = TfidfVectorizer( ngram_range=(1,2), min_df=0.01, \n",
        "                        max_df=0.75, stop_words='english', sublinear_tf=True)\n",
        "ratings = df_movies['rating_text'].values\n",
        "X_rating = vector_rating.fit_transform(ratings)\n",
        "X_rating = X_rating.todense()\n",
        "X_rating= pd.DataFrame(data=X_rating, columns=vector_rating.get_feature_names_out())\n",
        "\n",
        "# Age Ratings Categories\n",
        "X_mpaa = df_movies[['rated_R','rated_PG', 'rated_PG13', 'rated_TVMA', 'rated_TV14']]\n",
        "\n",
        "# Genres\n",
        "X_genre = df_movies[genres]"
      ],
      "metadata": {
        "id": "VU2eWHSQmsAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging Features\n",
        "X_mov = df_movies[['Title', 'Year', 'D_Female']].join(X_vecs).join(X_cast, rsuffix='cs').\\\n",
        "  join(X_company, rsuffix='cp').join(X_dist, rsuffix='ds').\\\n",
        "  join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg').join(X_rating, rsuffix='rt').\\\n",
        "        join(X_mpaa).join(X_genre, rsuffix='gn')\n",
        "\n",
        "\n",
        "X_score = df_crevs[['Title', 'Year', 'score', 'title_year']].merge(X_mov, on=['Title', 'Year']).drop(columns=['Title'])\n",
        "X_score['TY_code'] = X_score['title_year'].factorize()[0]\n",
        "X_score = X_score.drop(columns=['title_year'])\n",
        "X_source = pd.get_dummies(df_crevs['source'])\n",
        "\n",
        "#Critics with more than 50 reviews\n",
        "X_author = pd.get_dummies(df_crevs['author'])\n",
        "X_author = X_author[X_author.columns[X_author.sum()>=100]]\n",
        "\n",
        "X_year = pd.get_dummies(df_crevs['Year'])"
      ],
      "metadata": {
        "id": "Bc4RLg-hmsAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating/loading a file for storing the results\n",
        "import os.path\n",
        "import json\n",
        "if os.path.exists(results_dir + 'critics_reg_results.json'):\n",
        "  with open(results_dir + 'critics_reg_results.json', 'r') as input_file:\n",
        "    critics_reg_results = json.load(input_file)\n",
        "else:\n",
        "  critics_reg_results = {}"
      ],
      "metadata": {
        "id": "1Qv7Kjd8IHfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to store regression results\n",
        "def reviews_reg_sum(reg_res,target_vars,target_locs):\n",
        "  results_sum = { 'main vars':target_vars, \n",
        "                 'coefs': [reg_res.params[x] for x in target_vars],\n",
        "                'std_errors': [reg_res.bse[x] for x in target_vars],\n",
        "                't_values': [reg_res.tvalues[x] for x in target_vars],\n",
        "                 'p_values': [reg_res.pvalues[x] for x in target_vars],\n",
        "                'conf_intervals': [ list(reg_res.conf_int().values[i]) for i in target_locs],\n",
        "                 'R_squared': reg_res.rsquared, 'adj R_squared': reg_res.rsquared_adj, 'N_Obs': reg_res.nobs}\n",
        "\n",
        "  return results_sum"
      ],
      "metadata": {
        "id": "ZC2aXPpZxnJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regressions: Female Director"
      ],
      "metadata": {
        "id": "do-bQZcZqRkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp  = df_crevs[['author', 'C_count']].drop_duplicates().reset_index(drop=True)"
      ],
      "metadata": {
        "id": "n9sUBLTVfY2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(df_temp['C_count']>100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIpmornrgN6C",
        "outputId": "2867b9f7-9ece-43c0-8540-51e1e8358af0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "370"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Base:  Movie Features: Yes, D_Female*Year FE: Yes,\n",
        "# critic & source FE: No , Critic*D_Female FE: No\n",
        "\n",
        "# Year * D_Female \n",
        "arr_year = X_year.to_numpy()\n",
        "arr_DFem = X_score['D_Female'].to_numpy()\n",
        "year_DFem = arr_year * arr_DFem[:,None]\n",
        "year_DFem_cols = ['DFem_' + str(name) for name in X_year.columns.values]\n",
        "X_year_DFem = pd.DataFrame(year_DFem, columns=year_DFem_cols, index=X_score.index.values)\n",
        "\n",
        "# Data\n",
        "data_ols = X_score.drop(columns='D_Female').join(X_year).join(X_year_DFem).dropna() \n",
        "y_ols = data_ols['score']\n",
        "X_ols = data_ols.drop(columns='score')\n",
        "\n",
        "# TY code is used to cluster standard errors\n",
        "TY = X_ols['TY_code'].values.astype(int)\n",
        "X_ols = X_ols.drop(columns=['TY_code'])\n",
        "\n",
        "y_ols.astype('float16')\n",
        "X_ols.astype('float16')\n",
        "\n",
        "reg_ols = sm.OLS(y_ols, X_ols) \n",
        "res_ols = reg_ols.fit(cov_type='cluster', cov_kwds={'groups': TY })\n",
        "\n",
        "target_vars = year_DFem_cols\n",
        "target_locs = [X_ols.columns.get_loc(var) for var in target_vars]\n",
        "\n",
        "ols_res_sum = reviews_reg_sum(res_ols,target_vars, target_locs)\n",
        "critics_reg_results.update( {'Base':ols_res_sum })\n",
        "\n",
        "with open(results_dir + 'critics_reg_results.json', 'w') as outfile:\n",
        "    json.dump(critics_reg_results, outfile)"
      ],
      "metadata": {
        "id": "QIQPp7auy-hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_crevs['post_2010'] = np.where(df_crevs['Year']>=2010,1,0)\n",
        "# Number of Reviews after 2010\n",
        "df_crevs['R_p2010'] = df_crevs.groupby(['author','post_2010'])['Title'].transform('count') * df_crevs['post_2010']\n",
        "# Max to set it to both pre and post 2010 observations\n",
        "df_crevs['NoR_p2010'] = df_crevs.groupby(['author'])['R_p2010'].transform('max')\n",
        "df_crevs = df_crevs.drop(columns={'post_2010', 'R_p2010'})"
      ],
      "metadata": {
        "id": "A9SshziFM9NI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Active Critics: D_Female: No, Movie Features: Yes, D_Female*Year FE: Yes\n",
        "# #, critic & source FE: Yes , Critic*D_Female FE:No\n",
        "\n",
        "# Year * D_Female \n",
        "arr_year = X_year.to_numpy()\n",
        "arr_DFem = X_score['D_Female'].to_numpy()\n",
        "year_DFem = arr_year * arr_DFem[:,None]\n",
        "year_DFem_cols = ['DFem_' + str(name) for name in X_year.columns.values]\n",
        "X_year_DFem = pd.DataFrame(year_DFem, columns=year_DFem_cols, index=X_score.index.values)\n",
        "\n",
        "\n",
        "data_ols = X_score.drop(columns='D_Female').join(X_year).join(X_year_DFem).\\\n",
        "          join(X_source,rsuffix='src_').join(X_author, rsuffix='auth_').\\\n",
        "          join(df_crevs['NoR_p2010']).dropna()\n",
        "\n",
        "data_ols= data_ols.loc[data_ols['NoR_p2010']>=100].drop(columns=['NoR_p2010'])\n",
        "\n",
        "y_ols = data_ols['score']\n",
        "X_ols = data_ols.drop(columns='score')\n",
        "TY = X_ols['TY_code'].values.astype(int)\n",
        "X_ols = X_ols.drop(columns=['TY_code'])\n",
        "\n",
        "y_ols.astype('float16')\n",
        "X_ols.astype('float16')\n",
        "\n",
        "reg_ols = sm.OLS(y_ols, X_ols) \n",
        "res_ols = reg_ols.fit(cov_type='cluster', cov_kwds={'groups': TY })\n",
        "\n",
        "target_vars = year_DFem_cols\n",
        "target_locs = [X_ols.columns.get_loc(var) for var in target_vars]\n",
        "\n",
        "ols_res_sum = reviews_reg_sum(res_ols,target_vars, target_locs)\n",
        "critics_reg_results.update( {'active_critics':ols_res_sum })\n",
        "\n",
        "with open(results_dir + 'critics_reg_results.json', 'w') as outfile:\n",
        "    json.dump(critics_reg_results, outfile)"
      ],
      "metadata": {
        "id": "e-J6ARjF5rXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Female Critics Only\n",
        "# DFem*Year: D_Female: No, Movie Features: Yes, D_Female*Year FE: Yes, critic & source FE: Yes , Critic*D_Female FE: No\n",
        "\n",
        "# Year * D_Female \n",
        "arr_year = X_year.to_numpy()\n",
        "arr_DFem = X_score['D_Female'].to_numpy()\n",
        "year_DFem = arr_year * arr_DFem[:,None]\n",
        "year_DFem_cols = ['DFem_' + str(name) for name in X_year.columns.values]\n",
        "X_year_DFem = pd.DataFrame(year_DFem, columns=year_DFem_cols, index=X_score.index.values)\n",
        "\n",
        "# Data\n",
        "data_ols = X_score.drop(columns='D_Female').join(X_year).join(X_year_DFem).\\\n",
        "            join(df_crevs['C_Female']).join(X_source,rsuffix='src_').\\\n",
        "            join(X_author, rsuffix='auth_').dropna() \n",
        "\n",
        "data_ols = data_ols.loc[data_ols['C_Female']==1]\n",
        "y_ols = data_ols['score']\n",
        "X_ols = data_ols.drop(columns='score')\n",
        "TY = X_ols['TY_code'].values.astype(int)\n",
        "X_ols = X_ols.drop(columns=['TY_code'])\n",
        "\n",
        "y_ols.astype('float16')\n",
        "X_ols.astype('float16')\n",
        "\n",
        "reg_ols = sm.OLS(y_ols, X_ols) \n",
        "res_ols = reg_ols.fit(cov_type='cluster', cov_kwds={'groups': TY })\n",
        "\n",
        "target_vars = year_DFem_cols\n",
        "target_locs = [X_ols.columns.get_loc(var) for var in target_vars]\n",
        "\n",
        "ols_res_sum = reviews_reg_sum(res_ols,target_vars, target_locs)\n",
        "critics_reg_results.update( {'Female_critics':ols_res_sum })\n",
        "\n",
        "with open(results_dir + 'critics_reg_results.json', 'w') as outfile:\n",
        "    json.dump(critics_reg_results, outfile)"
      ],
      "metadata": {
        "id": "7VQzyI9THVpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Male Critics Only\n",
        "# DFem*Year: D_Female: No, Movie Features: Yes, D_Female*Year FE: Yes, critic & source FE: No , Critic*D_Female FE: No\n",
        "\n",
        "# Year * D_Female \n",
        "arr_year = X_year.to_numpy()\n",
        "arr_DFem = X_score['D_Female'].to_numpy()\n",
        "year_DFem = arr_year * arr_DFem[:,None]\n",
        "year_DFem_cols = ['DFem_' + str(name) for name in X_year.columns.values]\n",
        "X_year_DFem = pd.DataFrame(year_DFem, columns=year_DFem_cols)\n",
        "\n",
        "# Data\n",
        "data_ols = X_score.drop(columns='D_Female').join(X_year).join(X_year_DFem).\\\n",
        "            join(df_crevs['C_Female']).join(X_source,rsuffix='src_').\\\n",
        "            join(X_author, rsuffix='auth_').dropna() \n",
        "data_ols = data_ols.loc[data_ols['C_Female']==0]\n",
        "y_ols = data_ols['score']\n",
        "X_ols = data_ols.drop(columns='score')\n",
        "TY = X_ols['TY_code'].values.astype(int)\n",
        "X_ols = X_ols.drop(columns=['TY_code'])\n",
        "\n",
        "y_ols.astype('float16')\n",
        "X_ols.astype('float16')\n",
        "\n",
        "reg_ols = sm.OLS(y_ols, X_ols) \n",
        "res_ols = reg_ols.fit(cov_type='cluster', cov_kwds={'groups': TY })\n",
        "\n",
        "target_vars = year_DFem_cols\n",
        "target_locs = [X_ols.columns.get_loc(var) for var in target_vars]\n",
        "\n",
        "ols_res_sum = reviews_reg_sum(res_ols,target_vars, target_locs)\n",
        "critics_reg_results.update( {'Male_critics':ols_res_sum })\n",
        "\n",
        "with open(results_dir + 'critics_reg_results.json', 'w') as outfile:\n",
        "    json.dump(critics_reg_results, outfile)"
      ],
      "metadata": {
        "id": "vjD8eqwPM95P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Regression: Female Director and Actors"
      ],
      "metadata": {
        "id": "SSUBp4tjVue6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging Features\n",
        "X_mov_A = df_movies[['Title', 'Year', 'D_Female','A1_Female', 'A2_Female', 'A3_Female']].join(X_vecs).join(X_cast, rsuffix='cs').\\\n",
        "  join(X_company, rsuffix='cp').join(X_dist, rsuffix='ds').\\\n",
        "  join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg').join(X_rating, rsuffix='rt').\\\n",
        "        join(X_mpaa).join(X_genre, rsuffix='gn')\n",
        "\n",
        "\n",
        "X_score_A = df_crevs[['Title', 'Year', 'score', 'title_year']].merge(X_mov_A, on=['Title', 'Year']).drop(columns=['Title'])\n",
        "X_score_A['TY_code'] = X_score_A['title_year'].factorize()[0]\n",
        "X_score_A = X_score_A.drop(columns=['title_year'])"
      ],
      "metadata": {
        "id": "jZdg7IK8XkKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DFem*Year: D_Female: No, Movie Features: Yes, D_Female*Year FE: Yes, critic & source FE: No , Critic*D_Female FE: No\n",
        "\n",
        "# # Year * D_Female \n",
        "arr_year = X_year.to_numpy()\n",
        "arr_DFem = X_score_A['D_Female'].to_numpy()\n",
        "year_DFem = arr_year * arr_DFem[:,None]\n",
        "year_DFem_cols = ['DFem_' + str(name) for name in X_year.columns.values]\n",
        "X_year_DFem = pd.DataFrame(year_DFem, columns=year_DFem_cols, index=X_score_A.index.values)\n",
        "\n",
        "# Year * A1_Female \n",
        "arr_A1Fem = X_score_A['A1_Female'].to_numpy()\n",
        "year_A1Fem = arr_year * arr_A1Fem[:,None]\n",
        "year_A1Fem_cols = ['A1Fem_' + str(name) for name in X_year.columns.values]\n",
        "X_year_A1Fem = pd.DataFrame(year_A1Fem, columns=year_A1Fem_cols, index=X_score_A.index.values)\n",
        "\n",
        "# Year * A2_Female \n",
        "arr_A2Fem = X_score_A['A2_Female'].to_numpy()\n",
        "year_A2Fem = arr_year * arr_A2Fem[:,None]\n",
        "year_A2Fem_cols = ['A2Fem_' + str(name) for name in X_year.columns.values]\n",
        "X_year_A2Fem = pd.DataFrame(year_A2Fem, columns=year_A2Fem_cols, index=X_score_A.index.values)\n",
        "\n",
        "# Year * A3_Female \n",
        "arr_A3Fem = X_score_A['A3_Female'].to_numpy()\n",
        "year_A3Fem = arr_year * arr_A3Fem[:,None]\n",
        "year_A3Fem_cols = ['A3Fem_' + str(name) for name in X_year.columns.values]\n",
        "X_year_A3Fem = pd.DataFrame(year_A3Fem, columns=year_A3Fem_cols, index=X_score_A.index.values)\n",
        "\n",
        "# # Data\n",
        "\n",
        "data_ols = X_score.drop(columns='D_Female').join(X_year).join(X_year_DFem).join(X_year_A1Fem).\\\n",
        "            join(X_year_A2Fem).join(X_year_A3Fem).join(X_source,rsuffix='src_').\\\n",
        "            join(X_author, rsuffix='auth_').join(df_crevs['C_count']).dropna()\n",
        "\n",
        "# data_ols = data_ols.drop(columns='D_Female')\n",
        "data_ols= data_ols.loc[data_ols['C_count']>=100].drop(columns=['C_count'])\n",
        "\n",
        "\n",
        "y_ols = data_ols['score']\n",
        "X_ols = data_ols.drop(columns='score')\n",
        "TY = X_ols['TY_code'].values.astype(int)\n",
        "X_ols = X_ols.drop(columns=['TY_code'])\n",
        "\n",
        "\n",
        "reg_ols = sm.OLS(y_ols, X_ols) \n",
        "res_ols = reg_ols.fit(cov_type='cluster', cov_kwds={'groups': TY })\n",
        "\n",
        "DFem_vars = year_DFem_cols \n",
        "DFem_locs = [X_ols.columns.get_loc(var) for var in DFem_vars]\n",
        "ols_res_DFem = reviews_reg_sum(res_ols,DFem_vars, DFem_locs)\n",
        "\n",
        "A1Fem_vars = year_A1Fem_cols \n",
        "A1Fem_locs = [X_ols.columns.get_loc(var) for var in A1Fem_vars]\n",
        "ols_res_A1Fem = reviews_reg_sum(res_ols,A1Fem_vars, A1Fem_locs)\n",
        "\n",
        "A2Fem_vars = year_A2Fem_cols \n",
        "A2Fem_locs = [X_ols.columns.get_loc(var) for var in A2Fem_vars]\n",
        "ols_res_A2Fem = reviews_reg_sum(res_ols,A2Fem_vars, A2Fem_locs)\n",
        "\n",
        "A3Fem_vars = year_A3Fem_cols \n",
        "A3Fem_locs = [X_ols.columns.get_loc(var) for var in A3Fem_vars]\n",
        "ols_res_A3Fem = reviews_reg_sum(res_ols,A3Fem_vars, A3Fem_locs)\n",
        "\n",
        "ols_res_tot = {'DFem_Year': ols_res_DFem, 'A1Fem_Year': ols_res_A1Fem,\n",
        "               'A2Fem_Year': ols_res_A2Fem, 'A3Fem_Year': ols_res_A3Fem}\n",
        "critics_reg_results.update( {'DFem+AFem':ols_res_tot })\n",
        "\n",
        "with open(results_dir + 'critics_reg_results.json', 'w') as outfile:\n",
        "    json.dump(critics_reg_results, outfile)"
      ],
      "metadata": {
        "id": "A7ji6v22ZiPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Top Outlets"
      ],
      "metadata": {
        "id": "XMT2K8-RqwMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10 outlets with most reviews\n",
        "top_outlets = list(df_crevs['source'].value_counts()[:10].index.values)"
      ],
      "metadata": {
        "id": "O42Z4Lweq82U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top Outlet\n",
        "# DFem*Year: D_Female: No, Movie Features: Yes, D_Female*Year FE: Yes, critic & source FE: Yes , Critic*D_Female FE: No\n",
        "\n",
        "# Year * D_Female \n",
        "arr_year = X_year.to_numpy()\n",
        "arr_DFem = X_score['D_Female'].to_numpy()\n",
        "year_DFem = arr_year * arr_DFem[:,None]\n",
        "year_DFem_cols = ['DFem_' + str(name) for name in X_year.columns.values]\n",
        "X_year_DFem = pd.DataFrame(year_DFem, columns=year_DFem_cols, index=X_score.index.values)\n",
        "\n",
        "# Data\n",
        "data_ols = X_score.drop(columns='D_Female').join(X_year).join(X_year_DFem).\\\n",
        "            join(df_crevs['source']).join(X_source,rsuffix='src_').\\\n",
        "            join(X_author, rsuffix='auth_').dropna() \n",
        "\n",
        "data_ols['top_outlet'] = data_ols['source'].map(lambda x: 1 if x in top_outlets else 0)\n",
        "data_ols = data_ols.loc[data_ols['top_outlet']==1]\n",
        "y_ols = data_ols['score']\n",
        "X_ols = data_ols.drop(columns=['score', 'source', 'top_outlet'])\n",
        "TY = X_ols['TY_code'].values.astype(int)\n",
        "X_ols = X_ols.drop(columns=['TY_code'])\n",
        "\n",
        "y_ols.astype('float16')\n",
        "X_ols.astype('float16')\n",
        "\n",
        "reg_ols = sm.OLS(y_ols, X_ols) \n",
        "res_ols = reg_ols.fit(cov_type='cluster', cov_kwds={'groups': TY })\n",
        "\n",
        "target_vars = year_DFem_cols\n",
        "target_locs = [X_ols.columns.get_loc(var) for var in target_vars]\n",
        "\n",
        "ols_res_sum = reviews_reg_sum(res_ols,target_vars, target_locs)\n",
        "critics_reg_results.update( {'Top Outlets':ols_res_sum })\n",
        "\n",
        "with open(results_dir + 'critics_reg_results.json', 'w') as outfile:\n",
        "    json.dump(critics_reg_results, outfile)"
      ],
      "metadata": {
        "id": "4BZVCiOVEwRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_outlets_grading = pd.read_csv(data_dir + 'outlets_grading_system.csv')\n",
        "grading_outlets = df_outlets_grading.loc[((df_outlets_grading['trial 1']=='grade')\n",
        "                     & (df_outlets_grading['trial 2']=='grade'))]['source'].values.tolist()"
      ],
      "metadata": {
        "id": "mkOnbD7HXtvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Grading Outlets\n",
        "# DFem*Year: D_Female: No, Movie Features: Yes, D_Female*Year FE: Yes, critic &\n",
        "# source FE: Yes , Critic*D_Female FE: No\n",
        "\n",
        "# Year * D_Female \n",
        "arr_year = X_year.to_numpy()\n",
        "arr_DFem = X_score['D_Female'].to_numpy()\n",
        "year_DFem = arr_year * arr_DFem[:,None]\n",
        "year_DFem_cols = ['DFem_' + str(name) for name in X_year.columns.values]\n",
        "X_year_DFem = pd.DataFrame(year_DFem, columns=year_DFem_cols, index=X_score.index.values)\n",
        "\n",
        "# Data\n",
        "data_ols = X_score.drop(columns='D_Female').join(X_year).join(X_year_DFem).\\\n",
        "            join(df_crevs['source']).join(X_source,rsuffix='src_').\\\n",
        "            join(X_author, rsuffix='auth_').dropna() \n",
        "\n",
        "data_ols['grading_outlet'] = data_ols['source'].map(lambda x: 1 if x in grading_outlets else 0)\n",
        "data_ols = data_ols.loc[data_ols['grading_outlet']==1]\n",
        "y_ols = data_ols['score']\n",
        "X_ols = data_ols.drop(columns=['score', 'source', 'grading_outlet'])\n",
        "TY = X_ols['TY_code'].values.astype(int)\n",
        "X_ols = X_ols.drop(columns=['TY_code'])\n",
        "\n",
        "y_ols.astype('float16')\n",
        "X_ols.astype('float16')\n",
        "\n",
        "reg_ols = sm.OLS(y_ols, X_ols) \n",
        "res_ols = reg_ols.fit(cov_type='cluster', cov_kwds={'groups': TY })\n",
        "\n",
        "target_vars = year_DFem_cols\n",
        "target_locs = [X_ols.columns.get_loc(var) for var in target_vars]\n",
        "\n",
        "ols_res_sum = reviews_reg_sum(res_ols,target_vars, target_locs)\n",
        "critics_reg_results.update( {'Grading Outlets':ols_res_sum })\n",
        "\n",
        "with open(results_dir + 'critics_reg_results.json', 'w') as outfile:\n",
        "    json.dump(critics_reg_results, outfile)"
      ],
      "metadata": {
        "id": "bRI0KwUet6x7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_uscore =  df_crevs.merge(df_movies[['Title', 'Year' ,'userscore', 'N_user']],\n",
        "                           on =['Title','Year'])[['userscore', 'N_user']]\n",
        "\n",
        "X_uscore = X_score.join(X_uscore)"
      ],
      "metadata": {
        "id": "ge7BgKJFw7pJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Popular Movies\n",
        "# DFem*Year: D_Female: No, Movie Features: Yes, D_Female*Year FE: Yes, critic & source FE: Yes , Critic*D_Female FE: No\n",
        "\n",
        "# Year * D_Female \n",
        "arr_year = X_year.to_numpy()\n",
        "arr_DFem = X_uscore['D_Female'].to_numpy()\n",
        "year_DFem = arr_year * arr_DFem[:,None]\n",
        "year_DFem_cols = ['DFem_' + str(name) for name in X_year.columns.values]\n",
        "X_year_DFem = pd.DataFrame(year_DFem, columns=year_DFem_cols, index=X_uscore.index.values)\n",
        "\n",
        "# Data\n",
        "data_ols = X_uscore.drop(columns='D_Female').join(X_year).join(X_year_DFem).\\\n",
        "            join(df_crevs['source']).join(X_source,rsuffix='src_').\\\n",
        "            join(X_author, rsuffix='auth_').dropna() \n",
        "\n",
        "# The median number of user votes is 31 (32 for movies prior to 2010 and 30 for post 2010)\n",
        "data_ols = data_ols.loc[data_ols['N_user']>30]\n",
        "y_ols = data_ols['score']\n",
        "X_ols = data_ols.drop(columns=['score', 'source', 'userscore', 'N_user']) \n",
        "TY = X_ols['TY_code'].values.astype(int)\n",
        "X_ols = X_ols.drop(columns=['TY_code'])\n",
        "\n",
        "y_ols.astype('float16')\n",
        "X_ols.astype('float16')\n",
        "\n",
        "reg_ols = sm.OLS(y_ols, X_ols) \n",
        "res_ols = reg_ols.fit(cov_type='cluster', cov_kwds={'groups': TY })\n",
        "\n",
        "target_vars = year_DFem_cols\n",
        "target_locs = [X_ols.columns.get_loc(var) for var in target_vars]\n",
        "\n",
        "ols_res_sum = reviews_reg_sum(res_ols,target_vars, target_locs)\n",
        "critics_reg_results.update( {'N_user>30':ols_res_sum })\n",
        "\n",
        "with open(results_dir + 'critics_reg_results.json', 'w') as outfile:\n",
        "    json.dump(critics_reg_results, outfile)"
      ],
      "metadata": {
        "id": "ZaVplMO3e6B9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top Outlet & Popular Movies\n",
        "# DFem*Year: D_Female: No, Movie Features: Yes, D_Female*Year FE: Yes, critic & \n",
        "# source FE: Yes , Critic*D_Female FE: No\n",
        "\n",
        "# Year * D_Female \n",
        "arr_year = X_year.to_numpy()\n",
        "arr_DFem = X_uscore['D_Female'].to_numpy()\n",
        "year_DFem = arr_year * arr_DFem[:,None]\n",
        "year_DFem_cols = ['DFem_' + str(name) for name in X_year.columns.values]\n",
        "X_year_DFem = pd.DataFrame(year_DFem, columns=year_DFem_cols, index=X_uscore.index.values)\n",
        "\n",
        "# Data\n",
        "data_ols = X_uscore.drop(columns='D_Female').join(X_year).join(X_year_DFem).\\\n",
        "            join(df_crevs['source']).join(X_source,rsuffix='src_').\\\n",
        "            join(X_author, rsuffix='auth_').dropna() \n",
        "\n",
        "data_ols['top_outlet'] = data_ols['source'].map(lambda x: 1 if x in top_outlets else 0)\n",
        "data_ols = data_ols.loc[(data_ols['top_outlet']==1) & (data_ols['N_user']>30)]\n",
        "y_ols = data_ols['score']\n",
        "X_ols = data_ols.drop(columns=['score', 'source', 'top_outlet','userscore', 'N_user'])\n",
        "TY = X_ols['TY_code'].values.astype(int)\n",
        "X_ols = X_ols.drop(columns=['TY_code'])\n",
        "\n",
        "y_ols.astype('float16')\n",
        "X_ols.astype('float16')\n",
        "\n",
        "reg_ols = sm.OLS(y_ols, X_ols) \n",
        "res_ols = reg_ols.fit(cov_type='cluster', cov_kwds={'groups': TY })\n",
        "\n",
        "target_vars = year_DFem_cols\n",
        "target_locs = [X_ols.columns.get_loc(var) for var in target_vars]\n",
        "\n",
        "ols_res_sum = reviews_reg_sum(res_ols,target_vars, target_locs)\n",
        "critics_reg_results.update( {'Top Outlets & Popular Movies':ols_res_sum })\n",
        "\n",
        "with open(results_dir + 'critics_reg_results.json', 'w') as outfile:\n",
        "    json.dump(critics_reg_results, outfile)"
      ],
      "metadata": {
        "id": "xxamrRGrLKTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_outlets_list = df_crevs['source'].value_counts()[:10].index.tolist()\n",
        "# Coverage NY POST is from 1996, and Village Voice up to 2019\n",
        "top_outlets_list = list(set(top_outlets_list) - { 'Village Voice','New York Post'})\n",
        "top_outlets_set = set(top_outlets_list)"
      ],
      "metadata": {
        "id": "kyK-14XopKmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_crevs['pool_sources'] = df_crevs.groupby('title_year')['source'].transform(lambda x: '+'.join(x))\n",
        "df_crevs['pool_sources'] = df_crevs['pool_sources'].map(lambda x: set(x.split('+')))\n",
        "df_crevs['all_top_outlets'] = df_crevs['pool_sources'].map(lambda x: top_outlets_set.issubset(x))\n",
        "df_crevs['top_outlet'] = df_crevs['source'].isin(top_outlets_list)"
      ],
      "metadata": {
        "id": "E658sYUBu-gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#movies appeared in every top oputlets:\n",
        "# N\n",
        "# DFem*Year: D_Female: No, Movie Features: Yes, D_Female*Year FE: Yes, critic & \n",
        "# source FE: Yes , Critic*D_Female FE: No\n",
        "\n",
        "# Year * D_Female \n",
        "arr_year = X_year.to_numpy()\n",
        "arr_DFem = X_score['D_Female'].to_numpy()\n",
        "year_DFem = arr_year * arr_DFem[:,None]\n",
        "year_DFem_cols = ['DFem_' + str(name) for name in X_year.columns.values]\n",
        "X_year_DFem = pd.DataFrame(year_DFem, columns=year_DFem_cols, index=X_uscore.index.values)\n",
        "\n",
        "# Data\n",
        "data_ols = X_score.drop(columns='D_Female').join(X_year).join(X_year_DFem).\\\n",
        "            join(df_crevs[['source','top_outlet','all_top_outlets']]).dropna() \n",
        "\n",
        "# The median number of user votes is 31\n",
        "data_ols = data_ols.loc[(data_ols['all_top_outlets']==True) & (data_ols['top_outlet']==1)]\n",
        "y_ols = data_ols['score']\n",
        "X_ols = data_ols.drop(columns=['score', 'source', 'all_top_outlets', 'top_outlet']) \n",
        "TY = X_ols['TY_code'].values.astype(int)\n",
        "X_ols = X_ols.drop(columns=['TY_code'])\n",
        "\n",
        "y_ols.astype('float16')\n",
        "X_ols.astype('float16')\n",
        "\n",
        "reg_ols = sm.OLS(y_ols, X_ols) \n",
        "res_ols = reg_ols.fit(cov_type='cluster', cov_kwds={'groups': TY })\n",
        "\n",
        "target_vars = year_DFem_cols\n",
        "target_locs = [X_ols.columns.get_loc(var) for var in target_vars]\n",
        "\n",
        "ols_res_sum = reviews_reg_sum(res_ols,target_vars, target_locs)\n",
        "critics_reg_results.update( {'All Top Outlets':ols_res_sum })\n",
        "\n",
        "with open(results_dir + 'critics_reg_results.json', 'w') as outfile:\n",
        "    json.dump(critics_reg_results, outfile)"
      ],
      "metadata": {
        "id": "cyRJTXMdyBd9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}