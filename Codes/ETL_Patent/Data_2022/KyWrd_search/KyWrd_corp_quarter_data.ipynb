{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBClH1X7sz0RrCFt6mvG1x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahyarhabibi/GenderGaps_Hollywood/blob/main/Codes/ETL_Patent/Data_2022/KyWrd_search/KyWrd_corp_quarter_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7FjVjK4XXJ4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxdgyprhXzti",
        "outputId": "8913ac5b-0ec3-4baa-f329-31781c5be43d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct Corp-Quarter Level ML Patent Data."
      ],
      "metadata": {
        "id": "qeCOUONrbArm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir =  '/content/gdrive/MyDrive/Research/AI_innovation/Data/Patents/ML_Patents_KyWrd'"
      ],
      "metadata": {
        "id": "KYCj8SNTX4PW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading and Pre-Processing\n",
        "df_mlpat = pd.read_parquet(os.path.join(data_dir, \n",
        "                                        'KyWrd_patents_merged_info.parquet'))\n",
        "\n",
        "#spelling mistake in column\n",
        "df_mlpat = df_mlpat.rename(columns={'assing_addr': 'assign_addr'})\n",
        "\n",
        "df_mlpat['patent_date'] = pd.to_datetime(df_mlpat['patent_date'],\n",
        "                                        format = \"%Y-%m-%d\")\n",
        "\n",
        "df_mlpat['filing_date'] = pd.to_datetime(df_mlpat['filing_date'],\n",
        "                                        format = \"%Y-%m-%d\")\n",
        "df_mlpat['patent_year'] = df_mlpat['patent_date'].dt.year\n",
        "df_mlpat['file_year'] = df_mlpat['filing_date'].dt.year\n",
        "df_mlpat['file_quart'] = df_mlpat['filing_date'].dt.quarter\n",
        "# Remove Obs filed before 2010 or after 2019\n",
        "df_mlpat = df_mlpat.loc[(df_mlpat['file_year']>=2010) &\n",
        "                     (df_mlpat['file_year']<=2019)]\n",
        "\n",
        "# Remove withdrawn patents\n",
        "df_mplat = df_mlpat[df_mlpat['withdrawn']==0]     \n",
        "df_mlpat.drop(columns='withdrawn', inplace=True)\n",
        "\n",
        "# Remove Reissue patents\n",
        "df_mlpat = df_mlpat[ df_mlpat['patent_type']!='reissue']\n",
        "df_mlpat.drop(columns='patent_type', inplace=True)\n",
        "\n",
        "# Reset Index\n",
        "df_mlpat  = df_mlpat.reset_index(drop=True)\n",
        "\n",
        "# count citations\n",
        "df_mlpat['citation'] = df_mlpat['cited_by'].apply(lambda x: len(x) if x is not None\n",
        "                                                  else 0)\n"
      ],
      "metadata": {
        "id": "LNoPNJ_dz4Up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The subset assigned to organizations\n",
        "df_patorg = df_mlpat.loc[~ df_mlpat['assign_org'].isna()].reset_index(drop=True)\n",
        "\n",
        "\n",
        "# explode the patents assigned to multiple orgs\n",
        "\n",
        "keepvars = ['patent_id', 'patent_year', 'file_year', 'file_quart',\n",
        "            'kyw_desc_dl', 'kyw_desc_ml', 'kyw_desc_app', 'kyw_sum_dl',\n",
        "            'kyw_sum_ml', 'kyw_sum_app', 'assign_id', 'assign_org',\n",
        "            'assign_type', 'assign_addr','citation' ]\n",
        "\n",
        "df_corps = df_patorg[keepvars].explode(['assign_id', 'assign_org',\n",
        "                                        'assign_type', 'assign_addr'])\n",
        "\n",
        "# Keep US or Int. corporations\n",
        "df_corps = df_corps[((df_corps['assign_type']==2 )|\n",
        "                     (df_corps['assign_type']==3)) ].reset_index(drop=True)\n",
        "\n",
        "# Location\n",
        "df_corps['country'] = df_corps['assign_addr'].apply(lambda x: x['country'])\n",
        "df_corps['state'] = df_corps['assign_addr'].apply(lambda x: x['state'])\n",
        "df_corps['city'] = df_corps['assign_addr'].apply(lambda x: x['city'])"
      ],
      "metadata": {
        "id": "YmVo3ckFe6a5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data of unique corps names and locations per assign id \n",
        "corpvar = ['assign_id', 'file_year' ,'assign_org', 'country', 'state',\n",
        "                          'city']\n",
        "\n",
        "df_corps_char = df_corps[corpvar].sort_values(by=['assign_id', 'file_year'],\n",
        "                                              ascending=True)\n",
        "\n",
        "df_corps_char = df_corps_char.drop_duplicates(subset='assign_id', keep='last')\n",
        "df_corps_char = df_corps_char.drop(columns='file_year')"
      ],
      "metadata": {
        "id": "kQrH8X145bJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregate Patent data\n",
        "df_corps_gp = df_corps.groupby(by=['assign_id','file_year',  'file_quart'])\\\n",
        "                                   ['kyw_desc_dl','kyw_desc_ml', 'kyw_desc_app',\n",
        "                                    'kyw_sum_dl', 'kyw_sum_ml','kyw_sum_app',\n",
        "                                    'citation'].sum().reset_index()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EhzmKnbtsnp",
        "outputId": "510d1cbe-a9ec-4c03-8adb-e91a47bcd827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# simple use of groupby ommites quarter when a corp has not applied for any patents\n",
        "# create complete corp-quarter data\n",
        "df_yr_qrt = df_corps[['file_year', 'file_quart']].drop_duplicates().\\\n",
        "            reset_index(drop=True)\n",
        "assert len(df_yr_qrt)==40\n",
        "\n",
        "df_corp_qrt = df_corps_char.merge(df_yr_qrt, how='cross')\n",
        "\n",
        "# merged with grouped corporate-quarter data\n",
        "df_corp_qrt = df_corp_qrt.merge(df_corps_gp, on=['assign_id',  'file_year', \n",
        "                                                 'file_quart'], how='left')"
      ],
      "metadata": {
        "id": "qWz08euC4ixZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fill missing values with zero\n",
        "cols = ['kyw_desc_dl', 'kyw_desc_ml','kyw_desc_app', 'kyw_sum_dl',\n",
        "             'kyw_sum_ml', 'kyw_sum_app', 'citation']\n",
        "for col in cols:\n",
        "  df_corp_qrt[col] = df_corp_qrt[col].fillna(0)\n",
        "\n",
        "# rename columns\n",
        "df_corp_qrt.rename(columns={'kyw_desc_dl': 'desc_dl', 'kyw_desc_ml': 'desc_ml',\n",
        "                            'kyw_desc_app': 'desc_app','kyw_sum_dl': 'sum_dl',\n",
        "                            'kyw_sum_ml': 'sum_ml','kyw_sum_app': 'sum_app'},\n",
        "                   inplace=True)\n",
        "\n",
        "# save dataframe\n",
        "df_corp_qrt.to_parquet(os.path.join(data_dir, 'KyWrd_corp_quarter.parquet'))"
      ],
      "metadata": {
        "id": "W3xZEwCztGCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HfzzYR9Y_-kZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Corp-Quarter All Corps All Patents"
      ],
      "metadata": {
        "id": "5zwVr5Zuifrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "app_data = '/content/gdrive/MyDrive/Research/USPTO/Patents/Patents_Update2022/g_application.tsv.zip'\n",
        "assignee_data = '/content/gdrive/MyDrive/Research/USPTO/Patents/Patents_Update2022/g_assignee_disambiguated.tsv.zip'\n",
        "UScite_data = '/content/gdrive/MyDrive/Research/USPTO/Patents/Patents_Update2022/g_us_patent_citation.tsv.zip'\n",
        "patent_data = '/content/gdrive/MyDrive/Research/USPTO/Patents/Patents_Update2022/g_patent.tsv.zip'"
      ],
      "metadata": {
        "id": "YfF8yWJLioKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applications\n",
        "df_app = pd.read_csv(app_data, sep='\\t', usecols=['patent_id', 'filing_date'],\n",
        "                      dtype={'patent_id': object})\n",
        "\n",
        "df_app['filing_date'] = pd.to_datetime(df_app['filing_date'],\n",
        "                                        format = \"%Y-%m-%d\", errors='coerce')\n",
        "df_app['file_year'] = df_app['filing_date'].dt.year\n",
        "df_app = df_app[df_app['file_year']>=2010].reset_index(drop=True)\n",
        "\n",
        "# Patents\n",
        "df_pat = pd.read_csv(patent_data, sep='\\t', usecols=['patent_id', 'patent_type',\n",
        "                      'withdrawn'], dtype={'patent_id': object})\n",
        "\n",
        "# Merge and clean\n",
        "df_pat_app = df_app.merge(df_pat, on='patent_id')\n",
        "df_pat_app =df_pat.copy()\n",
        "df_pat_app = df_pat_app[df_pat_app['withdrawn']==0]\n",
        "df_pat_app = df_pat_app[df_pat_app['patent_type']!='reissue']\n",
        "df_pat_app.drop(columns='withdrawn', inplace=True)"
      ],
      "metadata": {
        "id": "p2goNuFVkZZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assignee data\n",
        "df_ass = pd.read_csv(assignee_data, sep='\\t', dtype={'patent_id':  object},\n",
        "                     usecols=['patent_id','assignee_id','assignee_type',\n",
        "                              'disambig_assignee_organization']).rename(\n",
        "                                  columns={ 'disambig_assignee_organization':\n",
        "                                    'org_name'} )\n",
        "\n",
        "# keep corps\n",
        "df_ass = df_ass[((df_ass['assignee_type']==2) | (df_ass['assignee_type']==3))]\n",
        "df_ass.drop(columns='assignee_type', inplace=True)\n",
        "df_pat_org = df_pat_app.merge(df_ass, on='patent_id', how='inner')"
      ],
      "metadata": {
        "id": "1VVLEcbPluvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many times each patent has been cited\n",
        "data_cite = pd.read_csv(UScite_data, sep='\\t', iterator=True, chunksize=1000000,\n",
        "                        usecols=['patent_id', 'citation_patent_id'], \n",
        "                        dtype={'patent_id': object,\n",
        "                               'citation_patent_id': object})\n",
        "\n",
        "patent_ids = df_pat_org['patent_id'].values.tolist()\n",
        "df_cite = pd.DataFrame(columns=['patent_id', 'citation_patent_id'])\n",
        "\n",
        "for n, chunk in enumerate(data_cite):\n",
        "  df_temp = chunk[chunk['citation_patent_id'].isin(patent_ids)]\n",
        "  df_cite = df_cite.append(df_temp)\n",
        "\n",
        "df_cite_gp = df_cite.groupby('citation_patent_id')['patent_id'].count().reset_index()\n",
        "df_cite_gp.rename(columns={'citation_patent_id': 'patent_id', \n",
        "                           'patent_id': 'N_citation'}, inplace=True)\n",
        "\n",
        "df_pat_org = df_pat_org.merge(df_cite_gp, on='patent_id', how='left')\n",
        "df_pat_org['N_citation'].fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "RkG2cA4tqrN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save DataFrame\n",
        "output_dir = '/content/gdrive/MyDrive/Research/AI_innovation/Data/Patents'\n",
        "df_pat_org.to_parquet(os.path.join(output_dir, 'Corps_all_patents.parquet'))"
      ],
      "metadata": {
        "id": "GSzCvMGGznf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pat_org = pd.read_parquet(os.path.join(output_dir, 'Corps_all_patents.parquet'))"
      ],
      "metadata": {
        "id": "duVVj13_ZB-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# aggregate to corp-quarter level\n",
        "df_pat_org['file_quart'] = df_pat_org['filing_date'].dt.quarter"
      ],
      "metadata": {
        "id": "ApQ8LdU803zU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collapse Patent data to Corp-Quarter level\n",
        "df_pat_org_gp = df_pat_org.groupby(['assignee_id', 'file_year', 'file_quart']).\\\n",
        "                agg({'patent_id':'count', 'N_citation': 'sum'}).reset_index().\\\n",
        "                rename(columns={'patent_id': 'N_patent'}) \n",
        "                \n",
        "# Data of unique corps names and locations per assign id \n",
        "corpvar = ['assignee_id', 'file_year', 'org_name']\n",
        "\n",
        "df_corps_char = df_pat_org[corpvar].sort_values(by=['assignee_id', 'file_year'],\n",
        "                                              ascending=True)\n",
        "\n",
        "df_corps_char = df_corps_char.drop_duplicates(subset='assignee_id', keep='last')\n",
        "df_corps_char = df_corps_char.drop(columns='file_year')\n",
        "# create complete corp-quarter base dataset\n",
        "df_yr_qrt = df_pat_org[['file_year', 'file_quart']].drop_duplicates().\\\n",
        "            reset_index(drop=True)\n",
        "\n",
        "df_corp_qrt = df_corps_char.merge(df_yr_qrt, how='cross')\n",
        "\n",
        "# merge with grouped corporate-quarter data\n",
        "df_corp_qrt = df_corp_qrt.merge(df_pat_org_gp, on=['assignee_id',  'file_year', \n",
        "                                                 'file_quart'], how='left')\n",
        "# fill missing values with zero\n",
        "cols = ['N_patent', 'N_citation']\n",
        "for col in cols:\n",
        "  df_corp_qrt[col] = df_corp_qrt[col].fillna(0)\n",
        "\n",
        "# save dataframe\n",
        "df_corp_qrt.to_parquet(os.path.join(output_dir, 'Corp_quarter_all_patents.parquet'))"
      ],
      "metadata": {
        "id": "OoNSacuRcmWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hAjijb8efBOA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}