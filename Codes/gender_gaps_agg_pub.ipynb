{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahyarhabibi/GenderGaps_Hollywood/blob/main/Codes/gender_gaps_agg_pub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook generates the results shown in Table 2 and Table 3 in the paper, estimating gender gaps in box office sales, budgets, critic and user scores ,and the impact of the \\#MeToo movement on these outcomes."
      ],
      "metadata": {
        "id": "Y7eBILTmXRSx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e7ATRuCVwFnn"
      },
      "outputs": [],
      "source": [
        "seed = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yLnEfBcAg6GO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import scipy as sc\n",
        "import statsmodels.api as sm\n",
        "from patsy import dmatrices\n",
        "import re\n",
        "import os\n",
        "import sympy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuWlE3LyWIn4",
        "outputId": "bd373bbe-46f9-444d-cca8-11c62a5dc230"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting DoubleML\n",
            "  Downloading DoubleML-0.5.0-py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from DoubleML) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from DoubleML) (1.3.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from DoubleML) (1.2.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from DoubleML) (0.12.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from DoubleML) (1.21.6)\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->DoubleML) (2022.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->DoubleML) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->DoubleML) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->DoubleML) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->DoubleML) (3.1.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels->DoubleML) (0.5.2)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=e8acd865754a2a68c9b1051c1b538c04591aa14131388c50421555004aa61221\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn, DoubleML\n",
            "Successfully installed DoubleML-0.5.0 sklearn-0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U DoubleML\n",
        "\n",
        "from doubleml import DoubleMLData\n",
        "from doubleml import DoubleMLPLR\n",
        "from doubleml import DoubleMLIRM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "B4bUU9grQ9_O"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import clone\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression as OLS\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "\n",
        "from xgboost import XGBClassifier, XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zr9zt0AMhrJb",
        "outputId": "c539321e-a9c8-4c40-e725-b0fb361cee6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3sl52CKHD2kg"
      },
      "outputs": [],
      "source": [
        "# Directories to read data and store results\n",
        "#Please add the parent folder to your Google Drive\n",
        "# Public Link: https://drive.google.com/drive/folders/1TYCDAJOCiLZw4TObcLac5GnL5YtwYnUD?usp=sharing\n",
        "parent_dir = \"/content/gdrive/MyDrive/GenderGaps_Hollywood/\" # You may need to change the address\n",
        "data_dir = os.path.join(parent_dir, 'Data/')\n",
        "results_dir = os.path.join(parent_dir,'Results/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Nj8NmyV8hsLf"
      },
      "outputs": [],
      "source": [
        "df_movies = pd.read_pickle(data_dir + 'movies_info_merged_MIW_pkl.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "a69EbzIzifUO"
      },
      "outputs": [],
      "source": [
        "genres = set(df_movies['genre'].sum())\n",
        "for gen in genres:\n",
        "    df_movies[gen] = df_movies['genre'].map(lambda x: 1 if gen in x else 0)\n",
        "    \n",
        "df_movies = df_movies.rename(columns={'Film-Noir': 'FilmNoir', 'Sci-Fi': \n",
        "                                      'SciFi', 'Reality-TV': 'RealityTV',\n",
        "                                      'Talk-Show': 'TalkShow'})\n",
        "\n",
        "genres = genres - {'Film-Noir','Sci-Fi','Reality-TV', 'Talk-Show'}\n",
        "genres = list(genres.union({'FilmNoir','SciFi','RealityTV', 'TalkShow'}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "T0UniT66Pier"
      },
      "outputs": [],
      "source": [
        "# Creating/loading a file for storing the results\n",
        "import os.path\n",
        "import json\n",
        "if os.path.exists(results_dir + 'agg_outcomes_reg_results.json'):\n",
        "  with open(results_dir + 'agg_outcomes_reg_results.json', 'r') as input_file:\n",
        "   agg_outcomes_reg_results = json.load(input_file)\n",
        "else:\n",
        "  agg_outcomes_reg_results = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1JH5FNkOQjvp"
      },
      "outputs": [],
      "source": [
        "# Function to store DML results\n",
        "def store_dml_results(model_res, post_me2=False):\n",
        "  coef_DFem = model_res.coef[0]\n",
        "  se_DFem = model_res.se[0]\n",
        "  pval_DFem = model_res.pval[0]\n",
        "  if post_me2==True:\n",
        "    coef_pme2 = model_res.coef[1]\n",
        "    se_pme2 = model_res.se[1]\n",
        "    pval_pme2 = model_res.pval[1]\n",
        "  else: coef_pme2, se_pme2, pval_pme2 = np.nan, np.nan, np.nan\n",
        "\n",
        "  return {'coef D_Female': [coef_DFem, coef_pme2], 'se D_Female': [se_DFem, se_pme2],\n",
        "          'p-val D_Female': [pval_DFem, pval_pme2]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6cl3P_SuuLJk"
      },
      "outputs": [],
      "source": [
        "# Function to store OLS results\n",
        "def store_ols_results(reg_res,loc_DFem, loc_DFem_pme2=None, post_me2=False):\n",
        "  coef_DFem = reg_res.params[loc_DFem]\n",
        "  se_DFem = reg_res.bse[loc_DFem]\n",
        "  pval_DFem = reg_res.pvalues[loc_DFem]\n",
        "  r2 = reg_res.rsquared\n",
        "  r2_adj = reg_res.rsquared_adj\n",
        "  N_obs = reg_res.nobs\n",
        "  if post_me2==True:\n",
        "    coef_pme2 = reg_res.params[loc_DFem_pme2]\n",
        "    se_pme2 = reg_res.bse[loc_DFem_pme2]\n",
        "    pval_pme2 = reg_res.pvalues[loc_DFem_pme2]\n",
        "  else: coef_pme2, se_pme2, pval_pme2 = np.nan, np.nan, np.nan\n",
        "\n",
        "  return {'coef D_Female': [coef_DFem, coef_pme2], 'se D_Female': [se_DFem, se_pme2],\n",
        "          'p-val D_Female': [pval_DFem, pval_pme2], 'R2': r2, 'Adj R2': r2_adj,\n",
        "          'N Obs': N_obs}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AECYeaBQVGVV"
      },
      "source": [
        "## Sales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqp7IqXHVXdn"
      },
      "source": [
        "### OLS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "c9f4c9zh76ND"
      },
      "outputs": [],
      "source": [
        "# Temporarily Storing Results in dicts\n",
        "reg_sales_dml_results={}\n",
        "reg_sales_ols_results = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "IJV40ZxSx6XM"
      },
      "outputs": [],
      "source": [
        "# Removing Movies made by online streaming platforms\n",
        "online_platforms = ['Netflix', 'Amazon Studios','Hulu','Amazon Prime Video', \n",
        "                      'Disney+', 'HBO Max' ]\n",
        "df_movies['online_plt'] = df_movies['Distributor'].map(lambda x: 1 if x in \n",
        "                                                       online_platforms else 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RHmKEe4WCdCM"
      },
      "outputs": [],
      "source": [
        "df_boxoff = df_movies.loc[~((df_movies['est_sales'].isna()) | \n",
        "                            (df_movies['est_budget'].isna()) | \n",
        "                            ( df_movies['online_plt']==1))].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "LTVYQh_tRBhQ",
        "outputId": "4742a8d2-4349-4193-8f79-4c293f1ed729"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Year    metascore     N_review      english      made_us  \\\n",
              "count  5486.000000  5486.000000  5486.000000  5486.000000  5486.000000   \n",
              "mean   2007.039920    54.370944    26.824098     0.941305     0.859825   \n",
              "std       8.016713    17.488687    10.978750     0.235074     0.347200   \n",
              "min    1990.000000     1.000000     7.000000     0.000000     0.000000   \n",
              "25%    2001.000000    42.000000    18.000000     1.000000     1.000000   \n",
              "50%    2008.000000    55.000000    27.000000     1.000000     1.000000   \n",
              "75%    2014.000000    67.000000    35.000000     1.000000     1.000000   \n",
              "max    2021.000000   100.000000    67.000000     1.000000     1.000000   \n",
              "\n",
              "          D_Female   est_budget    est_sales  \n",
              "count  5152.000000  5486.000000  5486.000000  \n",
              "mean      0.102873    32.011008    85.730269  \n",
              "std       0.303822    40.256378   167.896973  \n",
              "min       0.000000     0.000003     0.000139  \n",
              "25%       0.000000     7.000000     4.091704  \n",
              "50%       0.000000    18.000000    25.090584  \n",
              "75%       0.000000    40.000000    91.744965  \n",
              "max       1.000000   317.000000  2847.246203  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-da4f6df5-30cb-4392-b42d-a866a2803763\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>metascore</th>\n",
              "      <th>N_review</th>\n",
              "      <th>english</th>\n",
              "      <th>made_us</th>\n",
              "      <th>D_Female</th>\n",
              "      <th>est_budget</th>\n",
              "      <th>est_sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5486.000000</td>\n",
              "      <td>5486.000000</td>\n",
              "      <td>5486.000000</td>\n",
              "      <td>5486.000000</td>\n",
              "      <td>5486.000000</td>\n",
              "      <td>5152.000000</td>\n",
              "      <td>5486.000000</td>\n",
              "      <td>5486.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2007.039920</td>\n",
              "      <td>54.370944</td>\n",
              "      <td>26.824098</td>\n",
              "      <td>0.941305</td>\n",
              "      <td>0.859825</td>\n",
              "      <td>0.102873</td>\n",
              "      <td>32.011008</td>\n",
              "      <td>85.730269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>8.016713</td>\n",
              "      <td>17.488687</td>\n",
              "      <td>10.978750</td>\n",
              "      <td>0.235074</td>\n",
              "      <td>0.347200</td>\n",
              "      <td>0.303822</td>\n",
              "      <td>40.256378</td>\n",
              "      <td>167.896973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1990.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2001.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>4.091704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2008.000000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>25.090584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2014.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>91.744965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2021.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>317.000000</td>\n",
              "      <td>2847.246203</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da4f6df5-30cb-4392-b42d-a866a2803763')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-da4f6df5-30cb-4392-b42d-a866a2803763 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-da4f6df5-30cb-4392-b42d-a866a2803763');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df_boxoff[['Year', 'metascore', 'N_review', 'english', 'made_us', 'D_Female',\n",
        "           'est_budget', 'est_sales']].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "QzNDqOaj2Q1f"
      },
      "outputs": [],
      "source": [
        "# XS_base: X_base of the Sales specification\n",
        "y_sales, XS_base = dmatrices('np.log(est_sales) ~  D_Female + C(Year)',\n",
        "                    data=df_boxoff, return_type='dataframe')\n",
        "\n",
        "# XGB throws error if '[]' are in columns names:\n",
        "year_cols = dict(zip([f'C(Year)[T.{y}]' for y in range(1991,2022)],\n",
        "                     [f'Year({y})' for y in range(1991,2022)] ))\n",
        "XS_base = XS_base.rename(columns = year_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "jk_8A3tlwxL_",
        "outputId": "6d23473d-feab-4b28-aa8a-95e3de1fd6cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       np.log(est_sales)\n",
              "count        5152.000000\n",
              "mean            2.719025\n",
              "std             2.515618\n",
              "min            -7.377759\n",
              "25%             1.454029\n",
              "50%             3.252073\n",
              "75%             4.516292\n",
              "max             7.954108"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f690597f-f4d4-4e94-b206-aaf535d054db\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>np.log(est_sales)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5152.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.719025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.515618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-7.377759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.454029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.252073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.516292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.954108</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f690597f-f4d4-4e94-b206-aaf535d054db')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f690597f-f4d4-4e94-b206-aaf535d054db button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f690597f-f4d4-4e94-b206-aaf535d054db');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Mean Dependant Variable\n",
        "y_sales.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IqTOMRYH4JgX"
      },
      "outputs": [],
      "source": [
        "# OLS Sales Baseline\n",
        "y_ols = y_sales.copy()\n",
        "X_ols = XS_base.copy()\n",
        "ols = sm.OLS(y_ols, X_ols) \n",
        "reg_res = ols.fit().get_robustcov_results()\n",
        "\n",
        "loc_DFem = X_ols.columns.get_loc('D_Female')\n",
        "reg_sales_ols_results.update({'Base': store_ols_results(reg_res,loc_DFem)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XJ_JD66Qkjq_"
      },
      "outputs": [],
      "source": [
        "#Countries\n",
        "df_boxoff['country_list'] = df_boxoff['country'].map(lambda x: re.sub(' ','',x)).\\\n",
        "                        map(lambda x: x.split(','))\n",
        "\n",
        "X_country = pd.DataFrame(mlb.fit_transform(df_boxoff['country_list']),\n",
        "             columns=mlb.classes_, index=df_boxoff.index)\n",
        "\n",
        "X_country = X_country[X_country.columns[X_country.sum()>=10]]\n",
        "\n",
        "#Language\n",
        "df_boxoff['lang_list'] = df_boxoff['language'].map(lambda x: re.sub(' ','',x)).\\\n",
        "                        map(lambda x: x.split(','))\n",
        "X_lang = pd.DataFrame(mlb.fit_transform(df_boxoff['lang_list']),\n",
        "             columns=mlb.classes_, index=df_boxoff.index)\n",
        "X_lang = X_lang[X_lang.columns[X_lang.sum()>=10]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YsLOBCjJ_snj"
      },
      "outputs": [],
      "source": [
        "# OLS Country and Language FE: Spec2\n",
        "y_ols = y_sales.copy()\n",
        "X_ols = XS_base.join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg')\n",
        "\n",
        "ols = sm.OLS(y_ols, X_ols) \n",
        "reg_res = ols.fit().get_robustcov_results()\n",
        "\n",
        "loc_DFem = X_ols.columns.get_loc('D_Female')\n",
        "reg_sales_ols_results.update({'spec2': store_ols_results(reg_res,loc_DFem)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "h80FTw4xhIKk"
      },
      "outputs": [],
      "source": [
        "# Plot Truncated SVD Vectors\n",
        "plot_vectors = [f'plot_vec{i}' for i in range(100)]\n",
        "X_vecs = df_boxoff[plot_vectors]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0ZUWs5mMEStA"
      },
      "outputs": [],
      "source": [
        "# spec3 = spec2 + Plot Vectors FE\n",
        "y_ols = y_sales.copy()\n",
        "X_ols = XS_base.join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg').join(X_vecs)\n",
        "\n",
        "ols = sm.OLS(y_ols, X_ols) \n",
        "reg_res = ols.fit().get_robustcov_results()\n",
        "\n",
        "loc_DFem = X_ols.columns.get_loc('D_Female')\n",
        "reg_sales_ols_results.update({'spec3': store_ols_results(reg_res,loc_DFem)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "gmlXqAjhC184"
      },
      "outputs": [],
      "source": [
        "# Companies with at least 10 movies\n",
        "X_company = pd.get_dummies(df_boxoff['company'])\n",
        "X_company = X_company[X_company.columns[X_company.sum()>=10]]\n",
        "\n",
        "# Distributors with at least 10 movies\n",
        "X_dist = pd.get_dummies(df_boxoff['Distributor'])\n",
        "X_dist = X_dist[X_dist.columns[X_dist.sum()>=10]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "f_jhyhFkDWy2"
      },
      "outputs": [],
      "source": [
        "# spec4:  spec3 + company and distributor FE\n",
        "y_ols = y_sales.copy()\n",
        "X_ols = XS_base.join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg').\\\n",
        "        join(X_vecs).join(X_company, rsuffix='cp').\\\n",
        "        join(X_dist, rsuffix='ds')\n",
        "\n",
        "ols = sm.OLS(y_ols, X_ols) \n",
        "reg_res = ols.fit().get_robustcov_results()\n",
        "\n",
        "loc_DFem = X_ols.columns.get_loc('D_Female')\n",
        "reg_sales_ols_results.update({'spec4': store_ols_results(reg_res,loc_DFem)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "kxjFYXM6IqHe"
      },
      "outputs": [],
      "source": [
        "#Cast\n",
        "X_cast = pd.DataFrame(mlb.fit_transform(df_boxoff['cast']),columns=mlb.classes_, index=df_boxoff.index)\n",
        "# Keeping actors whose names showed up at least 10 times\n",
        "X_cast = X_cast[X_cast.columns[X_cast.sum()>=10]]\n",
        "\n",
        "# Age Ratings Categories\n",
        "X_mpaa = df_boxoff[['rated_R','rated_PG', 'rated_PG13', 'rated_TVMA', 'rated_TV14']]\n",
        "\n",
        "# Genres\n",
        "X_genre = df_boxoff[genres]\n",
        "# X_genre is not full rank in sales and budget data\n",
        "_, inds = sympy.Matrix(X_genre.values).rref() # returns independent indices\n",
        "keep_ind = list(inds)\n",
        "X_genre = X_genre.iloc[:,keep_ind] # full-rank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "f56urnA1I5ue"
      },
      "outputs": [],
      "source": [
        "# spec5:  spec4 + cast + age ratigns, mpaa, and genres\n",
        "y_ols = y_sales.copy()\n",
        "X_ols = XS_base.join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg').\\\n",
        "        join(X_vecs).join(X_cast, rsuffix='cs').join(X_company, rsuffix='cp').\\\n",
        "        join(X_dist, rsuffix='ds').join(X_mpaa).join(X_genre, rsuffix='gn')\n",
        "\n",
        "ols = sm.OLS(y_ols, X_ols) \n",
        "reg_res = ols.fit().get_robustcov_results()\n",
        "\n",
        "loc_DFem = X_ols.columns.get_loc('D_Female')\n",
        "reg_sales_ols_results.update({'spec5': store_ols_results(reg_res,loc_DFem)})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg_sales_ols_results['spec5']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqu4Yj1o51lI",
        "outputId": "ba824a13-a6a9-472e-971a-788470fd6986"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'coef D_Female': [-0.15706103324758702, nan],\n",
              " 'se D_Female': [0.08466112788589993, nan],\n",
              " 'p-val D_Female': [0.06363980101081147, nan],\n",
              " 'R2': 0.7127836549652102,\n",
              " 'Adj R2': 0.6565804565287368,\n",
              " 'N Obs': 5152.0}"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2G1WniaVaGH"
      },
      "source": [
        "### DML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kh1F5Cv6h_wf",
        "outputId": "eb21d667-2f1a-4d08-8d66-30b28244f9f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Features: 843\n"
          ]
        }
      ],
      "source": [
        "# Using the complete set of features to estimate DML models\n",
        "XS_full = XS_base.join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg').\\\n",
        "        join(X_vecs).join(X_cast, rsuffix='cs').join(X_company, rsuffix='cp').\\\n",
        "        join(X_dist, rsuffix='ds').join(X_mpaa).join(X_genre, rsuffix='gn')\n",
        "\n",
        "data_sales = XS_full.join(y_sales)\n",
        "y_sales_dml = data_sales['np.log(est_sales)']\n",
        "data_sales = data_sales.rename(columns={'np.log(est_sales)': 'log_sales'})\n",
        "x_cols = list(set(data_sales.columns.values) - {'D_Female','log_sales' })\n",
        "\n",
        "dml_data_sales = DoubleMLData(data_sales, y_col = 'log_sales', d_cols = 'D_Female',\n",
        "                        x_cols = x_cols)\n",
        "\n",
        "print(f'Number of Features: {len(x_cols)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Mv3WaCs12_Rv"
      },
      "outputs": [],
      "source": [
        "# Since tuning models in DML takes time, I specified the tuned versions from the previous runs.\n",
        "# The codes for tuning the classifers can be found below.\n",
        "\n",
        "lgt_classifier = LogisticRegression(C=1000000.0, penalty='l1', random_state=1000,\n",
        "                   solver='liblinear')\n",
        "\n",
        "lgt_params = {'C': [1000000.0], 'penalty': ['l1']}\n",
        "\n",
        "ENet_tuned = ElasticNet(alpha=0.001, l1_ratio=0.75)\n",
        "\n",
        "RF_tuned = RandomForestRegressor(n_jobs = -1, n_estimators = 300, max_features = 'sqrt'\n",
        "                          , max_depth=80, min_samples_split= 8, random_state=seed)\n",
        "\n",
        "XGB_tuned = XGBRegressor(objective = \"reg:squarederror\", eta = 0.2,\n",
        "                        n_estimators =50, n_jobs=-1, max_depth= 10, random_state=seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvymwEuXGjlq"
      },
      "source": [
        " **NOTE**: DML uses the accuracy metric to tune the binary classifiern and not F1 score. \n",
        " Considering the accuracy metric, the model is best tuned when it predicts D_Female = 0\n",
        " for all movies to obtain a accuracy of 90%, but with a F1 equal to 0. Therefore, \n",
        " I tune the binary classifier outside of the DML Class. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "XhExUUHCaywi"
      },
      "outputs": [],
      "source": [
        "# # Tuning Classifier (learner_m):\n",
        "# # Selection Stage\n",
        "\n",
        "# d_fem = XS_full['D_Female']\n",
        "# X_cls = XS_full.drop(columns=['D_Female'])\n",
        "\n",
        "# param_grid = {'penalty': ['l2', 'l1'], \n",
        "#               'C': [ 1e5,1e6, 1e7, 1e8, 1e9]}\n",
        "\n",
        "# # Logit\n",
        "# lgt = LogisticRegression(solver='liblinear', random_state=seed)\n",
        "# clf = GridSearchCV(lgt, param_grid, scoring='f1',cv = ShuffleSplit(n_splits=5,random_state=seed))\n",
        "# clf.fit(X_cls, d_fem)\n",
        "# lgt_classifier = clf.best_estimator_\n",
        "# lgt_params = {'C': [clf.best_params_['C']], 'penalty': [clf.best_params_['penalty']]}\n",
        "\n",
        "# # F1 Test Scores are about 0.20\n",
        "# lgt_test_scores = cross_val_score(lgt_classifier,X_cls, d_fem, n_jobs=-1, scoring = 'f1',cv = ShuffleSplit(n_splits=5))\n",
        "# print(f'lgt_scores: {lgt_test_scores}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "96KT7ZfV8k0M"
      },
      "outputs": [],
      "source": [
        "# # Random Forests\n",
        "# rfc_scores = cross_val_score(RF_tuned,XS_full, y_sales, n_jobs=-1, scoring = 'r2',\n",
        "#                              cv = ShuffleSplit(n_splits=3))\n",
        "# print(f'rfc_scores: {rfc_scores}')\n",
        "\n",
        "# # XGBoost: TFIDF Matrix\n",
        "# xgb_scores =  cross_val_score(XGB_tuned,XS_full, y_sales, n_jobs=-1, scoring = 'r2',\n",
        "#                               cv = ShuffleSplit(n_splits=3))\n",
        "# print(f'xgb_scores: {xgb_scores}')\n",
        "\n",
        "# # Elastic Net: \n",
        "# elnet_scores = cross_val_score(ENet_tuned,XS_full, y_sales, n_jobs=-1, scoring = 'r2',cv = ShuffleSplit(n_splits=5))\n",
        "# print(f'elnet_scores: {elnet_scores}')\n",
        "\n",
        "# # CV R2 Summary: RF roughly 0.45, XGB roughly 0.50, Elastic Net: roughly 0.63"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "qjBG5cp8jiFy"
      },
      "outputs": [],
      "source": [
        "# DML 1\n",
        "np.random.seed(seed)\n",
        "# learner_g = ElasticNet()\n",
        "learner_g = ENet_tuned\n",
        "learner_m = lgt_classifier\n",
        "ml_g = clone(learner_g)\n",
        "ml_m = clone(learner_m)\n",
        "param_grids = {'ml_g': {'alpha': [0.0001, 0.001, 0.1], 'l1_ratio': [ 0.01,0.25,0.5,0.75,0.99]},\n",
        "              'ml_m': lgt_params}\n",
        "dml_sales = DoubleMLPLR(dml_data_sales, ml_g, ml_m)\n",
        "# dml_sales.tune(param_grids, n_folds_tune=3, n_jobs_cv=-1)\n",
        "dml_sales.fit(n_jobs_cv=-1, store_predictions=True);\n",
        "\n",
        "# Store Coef and SE\n",
        "reg_sales_dml_results.update({'ElasticNet': store_dml_results(dml_sales)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "6psnOjVOI4Jf"
      },
      "outputs": [],
      "source": [
        "# DML Random Forest\n",
        "np.random.seed(seed)\n",
        "# learner_g = RandomForestRegressor(n_jobs = -1, n_estimators = 300,\n",
        "#                                   max_features= 'sqrt')\n",
        "learner_g = RF_tuned\n",
        "learner_m = lgt_classifier\n",
        "ml_g = clone(learner_g)\n",
        "ml_m = clone(learner_m)\n",
        "\n",
        "param_grids = {'ml_g': {'max_depth': [ 20, 40, 80], 'min_samples_split': [4,8,16]},\n",
        "              'ml_m': lgt_params}\n",
        "\n",
        "dml_sales = DoubleMLPLR(dml_data_sales, ml_g, ml_m)\n",
        "# dml_sales.tune(param_grids, n_folds_tune=3, n_jobs_cv=-1)\n",
        "dml_sales.fit(n_jobs_cv=-1, store_predictions=True);\n",
        "\n",
        "# Store Coef and SE\n",
        "reg_sales_dml_results.update({'RandomForest': store_dml_results(dml_sales)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "tTIRE97-x4Lw"
      },
      "outputs": [],
      "source": [
        "# DML XGBoost\n",
        "np.random.seed(seed)\n",
        "# learner_g =  XGBRegressor(objective = \"reg:squarederror\",\n",
        "#                         n_estimators =50, n_jobs=-1, random_state=seed)\n",
        "learner_g = XGB_tuned\n",
        "learner_m = lgt_classifier\n",
        "ml_g = clone(learner_g)\n",
        "ml_m = clone(learner_m)\n",
        "param_grids = {'ml_g': {'max_depth': [10, 20, 30], 'eta': [0.2, 0.4, 0.6]},\n",
        "              'ml_m': lgt_params}\n",
        "\n",
        "dml_sales = DoubleMLPLR(dml_data_sales, ml_g, ml_m)\n",
        "# dml_sales.tune(param_grids, n_folds_tune=3, n_jobs_cv=-1)\n",
        "dml_sales.fit(n_jobs_cv=-1, store_predictions=True);\n",
        "\n",
        "# Store Coef and SE\n",
        "reg_sales_dml_results.update({'XGBoost': store_dml_results(dml_sales)})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Winsorized Regs"
      ],
      "metadata": {
        "id": "rFdvlwRAwaV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q01_sales = y_sales['np.log(est_sales)'].quantile(.01)\n",
        "q99_sales = y_sales['np.log(est_sales)'].quantile(.99)\n",
        "\n",
        "keep_indx = y_sales.loc[((y_sales['np.log(est_sales)']>q01_sales) & \n",
        "          (y_sales['np.log(est_sales)']<q99_sales))].index.values\n",
        "\n",
        "y_sales_win = y_sales.iloc[y_sales.index.isin(keep_indx)]\n",
        "XS_base_win = XS_base.iloc[y_sales.index.isin(keep_indx)]"
      ],
      "metadata": {
        "id": "e20rHjujtnLJ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Winsorized: full controls\n",
        "y_ols = y_sales_win.copy()\n",
        "X_ols = XS_base_win.join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg').\\\n",
        "        join(X_vecs).join(X_cast, rsuffix='cs').join(X_company, rsuffix='cp').\\\n",
        "        join(X_dist, rsuffix='ds').join(X_mpaa).join(X_genre, rsuffix='gn')\n",
        "\n",
        "ols = sm.OLS(y_ols, X_ols) \n",
        "reg_res = ols.fit().get_robustcov_results()\n",
        "\n",
        "loc_DFem = X_ols.columns.get_loc('D_Female')\n",
        "reg_sales_ols_results.update({'winsorized_reg': store_ols_results(reg_res,loc_DFem)})"
      ],
      "metadata": {
        "id": "yl1sZJ-iykeY"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quantile Regression"
      ],
      "metadata": {
        "id": "hvO0syb9umQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ys_qreg = y_sales.copy()\n",
        "XS_qreg = XS_base.join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg').\\\n",
        "        join(X_vecs).join(X_cast, rsuffix='cs').join(X_company, rsuffix='cp').\\\n",
        "        join(X_dist, rsuffix='ds').join(X_mpaa).join(X_genre, rsuffix='gn')"
      ],
      "metadata": {
        "id": "RZf4Uf8YGewR"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining quantile regression models\n",
        "qreg_model = sm.regression.quantile_regression.QuantReg(ys_qreg,XS_qreg)\n",
        "def qreg_fit(q):\n",
        "  res= qreg_model.fit(q)\n",
        "  return [q, res.params['D_Female'], res.bse['D_Female'], res.pvalues['D_Female']\n",
        "          ] +   res.conf_int().loc['D_Female'].tolist() \n"
      ],
      "metadata": {
        "id": "FQh0lnmeTMx1"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Estiamting quantile regression for q=0.1, 0.2, .... 0.9\n",
        "# # Takes a LONG time\n",
        "# quantiles = np.arange(0.1, 0.91,0.10)\n",
        "# qreg_results = [qreg_fit(q) for q in quantiles]\n",
        "# df_qreg_res = pd.DataFrame(qreg_results, columns=[\"q\", \"coef\", \"se\", \"p-val\", \"lb\", \"ub\"])\n",
        "# df_qreg_res.to_csv(results_dir + 'qreg_results_sales.csv')"
      ],
      "metadata": {
        "id": "2Op5rusXGbvN"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQalpY5W0LS_"
      },
      "source": [
        "### MeToo Impact"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "qwtjXG4O26Yz"
      },
      "outputs": [],
      "source": [
        "df_boxoff_me2= df_boxoff.copy()\n",
        "#post me too >=2018\n",
        "df_boxoff_me2['DFem_PMe2'] = np.where(((df_boxoff_me2['D_Female']==1) & (df_boxoff_me2['Year']>2017)), 1,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "tY_bryiz4b36"
      },
      "outputs": [],
      "source": [
        "# OLS\n",
        "# XS_base: X_base of the Sales specification\n",
        "y_sales, XS_me2 = dmatrices('np.log(est_sales) ~ D_Female + C(Year) + DFem_PMe2',\n",
        "                    data=df_boxoff_me2, return_type='dataframe')\n",
        "\n",
        "# OLS: Fully Saturated Model\n",
        "y_ols = y_sales.copy()\n",
        "X_ols = XS_me2.join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg').\\\n",
        "        join(X_vecs).join(X_cast, rsuffix='cs').join(X_company, rsuffix='cp').\\\n",
        "        join(X_dist, rsuffix='ds').join(X_mpaa).join(X_genre, rsuffix='gn')\n",
        "\n",
        "ols = sm.OLS(y_ols, X_ols) \n",
        "reg_res = ols.fit().get_robustcov_results()\n",
        "\n",
        "loc_DFem = X_ols.columns.get_loc('D_Female')\n",
        "loc_DFem_pme2 = X_ols.columns.get_loc('DFem_PMe2')\n",
        "reg_sales_ols_results.update({'metoo': \n",
        "                      store_ols_results(reg_res,loc_DFem,loc_DFem_pme2,\n",
        "                                        post_me2=True)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "JWTgb3LH6_4B"
      },
      "outputs": [],
      "source": [
        "# DML\n",
        "data_sales_me2 = X_ols.join(y_sales)\n",
        "data_sales_me2 = data_sales_me2.rename(columns={'np.log(est_sales)': 'log_sales'})\n",
        "x_cols_me2 = list(set(X_ols.columns.values) - {'D_Female', 'DFem_PMe2'})\n",
        "\n",
        "dml_data_sales_me2 = DoubleMLData(data_sales_me2, y_col = 'log_sales', d_cols =\n",
        "                                 ['D_Female','DFem_PMe2'], x_cols = x_cols_me2)\n",
        "\n",
        "# Double ML:\n",
        "# DML ElasticNet\n",
        "learner_g = ENet_tuned\n",
        "learner_m = lgt_classifier\n",
        "ml_g = clone(learner_g)\n",
        "ml_m = clone(learner_m)\n",
        "dml_sales = DoubleMLPLR(dml_data_sales_me2, ml_g, ml_m)\n",
        "dml_sales.fit(n_jobs_cv=-1, store_predictions=True);\n",
        "reg_sales_dml_results.update({'metoo(ENet)': store_dml_results(dml_sales, \n",
        "                                                                   post_me2=True)})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1Ow96Uc_soR"
      },
      "source": [
        "### Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "rzMnKXPd_vMd"
      },
      "outputs": [],
      "source": [
        "#Save Results\n",
        "reg_sales_results = {'OLS': reg_sales_ols_results, 'DML': reg_sales_dml_results}\n",
        "agg_outcomes_reg_results.update({'Sales': reg_sales_results})\n",
        "\n",
        "with open(results_dir + 'agg_outcomes_reg_results.json', 'w') as outfile:\n",
        "    json.dump(agg_outcomes_reg_results, outfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Nu5EGFiq9MIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "918cfc1b-2c04-46e2-ff1c-e27eebb6ab28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  app.launch_new_instance()\n"
          ]
        }
      ],
      "source": [
        "# Create DataFrame of the Results\n",
        "\n",
        "specs = list(reg_sales_ols_results.keys()) + list(reg_sales_dml_results.keys()) \n",
        "\n",
        "params_ols =  ['coef D_Female', 'se D_Female', 'p-val D_Female']\n",
        "params_dml =  ['coef D_Female', 'se D_Female', 'p-val D_Female']\n",
        "spec_ols = list(reg_sales_ols_results.keys() -{'metoo'})\n",
        "spec_dml = list(reg_sales_dml_results.keys() - {'metoo(ENet)'} )\n",
        "\n",
        "data_ols = [[reg_sales_ols_results[spec][p][0] for p in params_ols] for spec in spec_ols]\n",
        "data_r2 = [[reg_sales_ols_results[spec][p] for p in ['R2', 'N Obs']] for spec in spec_ols]\n",
        "data_ols = [data_ols[r] + data_r2[r] for r in range(len(data_ols))]\n",
        "\n",
        "data_dml = [[reg_sales_dml_results[spec][p][0] for p in params_dml] for spec in spec_dml]\n",
        "\n",
        "data_DFem = np.asarray(data_ols + data_dml )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "BTu_2mkLIvkk"
      },
      "outputs": [],
      "source": [
        "# Cast the results in tables\n",
        "table_ols_sales = pd.DataFrame(np.asarray(data_ols).T, columns= spec_ols,\n",
        "                               index = ['coef', 'SE', 'P-Val', 'R2', 'N'])\n",
        "\n",
        "table_dml_sales = pd.DataFrame(np.asarray(data_dml).T, columns= spec_dml,\n",
        "                               index = ['coef', 'SE', 'P-Val'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARN4QJzV3GFU"
      },
      "source": [
        "## Budget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "FW6QPvB432oe"
      },
      "outputs": [],
      "source": [
        "# Temporarily Storing Results\n",
        "reg_budget_dml_results={}\n",
        "reg_budget_ols_results={}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdEO3iHF33hW"
      },
      "source": [
        "### OLS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "pyElASlU4Ns3"
      },
      "outputs": [],
      "source": [
        "# XS_base: X_base of the Sales specification\n",
        "y_budget, XB_base = dmatrices('np.log(est_budget) ~  D_Female + C(Year)',\n",
        "                    data=df_boxoff, return_type='dataframe')\n",
        "\n",
        "# XGB throws error if '[]' are in columns names:\n",
        "year_cols = dict(zip([f'C(Year)[T.{y}]' for y in range(1991,2022)],\n",
        "                     [f'Year({y})' for y in range(1991,2022)] ))\n",
        "XB_base = XB_base.rename(columns = year_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "AsGFS_-l4Ns5"
      },
      "outputs": [],
      "source": [
        "# OLS Sales Baseline\n",
        "y_ols = y_budget.copy()\n",
        "X_ols = XB_base.copy()\n",
        "ols = sm.OLS(y_ols, X_ols) \n",
        "reg_res = ols.fit().get_robustcov_results()\n",
        "\n",
        "loc_DFem = X_ols.columns.get_loc('D_Female')\n",
        "reg_budget_ols_results.update({'Base': store_ols_results(reg_res,loc_DFem)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "XJVqNNWf4Ns6"
      },
      "outputs": [],
      "source": [
        "#Countries\n",
        "df_boxoff['country_list'] = df_boxoff['country'].map(lambda x: re.sub(' ','',x)).\\\n",
        "                        map(lambda x: x.split(','))\n",
        "\n",
        "X_country = pd.DataFrame(mlb.fit_transform(df_boxoff['country_list']),\n",
        "             columns=mlb.classes_, index=df_boxoff.index)\n",
        "\n",
        "X_country = X_country[X_country.columns[X_country.sum()>=10]]\n",
        "\n",
        "#Language\n",
        "df_boxoff['lang_list'] = df_boxoff['language'].map(lambda x: re.sub(' ','',x)).\\\n",
        "                        map(lambda x: x.split(','))\n",
        "X_lang = pd.DataFrame(mlb.fit_transform(df_boxoff['lang_list']),\n",
        "             columns=mlb.classes_, index=df_boxoff.index)\n",
        "X_lang = X_lang[X_lang.columns[X_lang.sum()>=10]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "PtNOxTvC4Ns7"
      },
      "outputs": [],
      "source": [
        "# OLS Country and Language FE: Spec2\n",
        "y_ols = y_budget.copy()\n",
        "X_ols = XS_base.join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg')\n",
        "\n",
        "ols = sm.OLS(y_ols, X_ols) \n",
        "reg_res = ols.fit().get_robustcov_results()\n",
        "\n",
        "loc_DFem = X_ols.columns.get_loc('D_Female')\n",
        "reg_budget_ols_results.update({'spec2': store_ols_results(reg_res,loc_DFem)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "o1Y08AmB4Ns7"
      },
      "outputs": [],
      "source": [
        "# Plot Truncated SVD Vectors\n",
        "plot_vectors = [f'plot_vec{i}' for i in range(100)]\n",
        "X_vecs = df_boxoff[plot_vectors]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "WE6S-EpD4Ns8"
      },
      "outputs": [],
      "source": [
        "# spec3 = spec2 + Plot Vectors FE\n",
        "y_ols = y_budget.copy()\n",
        "X_ols = XS_base.join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg').join(X_vecs)\n",
        "\n",
        "ols = sm.OLS(y_ols, X_ols) \n",
        "reg_res = ols.fit().get_robustcov_results()\n",
        "\n",
        "loc_DFem = X_ols.columns.get_loc('D_Female')\n",
        "reg_budget_ols_results.update({'spec3': store_ols_results(reg_res,loc_DFem)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "hh_bw8n74Ns9"
      },
      "outputs": [],
      "source": [
        "# Companies with at least 10 movies\n",
        "X_company = pd.get_dummies(df_boxoff['company'])\n",
        "X_company = X_company[X_company.columns[X_company.sum()>=10]]\n",
        "\n",
        "# Distributors with at least 10 movies\n",
        "X_dist = pd.get_dummies(df_boxoff['Distributor'])\n",
        "X_dist = X_dist[X_dist.columns[X_dist.sum()>=10]]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "xzp_VdKp4Ns-"
      },
      "outputs": [],
      "source": [
        "# spec4:  spec3 + company and distributorFE\n",
        "y_ols = y_budget.copy()\n",
        "X_ols = XS_base.join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg').\\\n",
        "        join(X_vecs).join(X_company, rsuffix='cp').\\\n",
        "        join(X_dist, rsuffix='ds')\n",
        "\n",
        "ols = sm.OLS(y_ols, X_ols) \n",
        "reg_res = ols.fit().get_robustcov_results()\n",
        "\n",
        "loc_DFem = X_ols.columns.get_loc('D_Female')\n",
        "reg_budget_ols_results.update({'spec4': store_ols_results(reg_res,loc_DFem)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "npvTj-Sg4Ns_"
      },
      "outputs": [],
      "source": [
        "#Cast\n",
        "X_cast = pd.DataFrame(mlb.fit_transform(df_boxoff['cast']),columns=mlb.classes_, index=df_boxoff.index)\n",
        "# Keeping actors whose names showed up at least 10 times\n",
        "X_cast = X_cast[X_cast.columns[X_cast.sum()>=10]]\n",
        "\n",
        "# Age Ratings Categories\n",
        "X_mpaa = df_boxoff[['rated_R','rated_PG', 'rated_PG13', 'rated_TVMA', 'rated_TV14']]\n",
        "\n",
        "# Genres\n",
        "X_genre = df_boxoff[genres]\n",
        "# X_genre is not full rank in sales and budget data\n",
        "_, inds = sympy.Matrix(X_genre.values).rref() # returns independent indices\n",
        "keep_ind = list(inds)\n",
        "X_genre = X_genre.iloc[:,keep_ind] # full-rank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "eCMDnOeY4NtA"
      },
      "outputs": [],
      "source": [
        "# spec5:  spec4 + cast +  age ratigns, mpaa, and genres\n",
        "y_ols = y_budget.copy()\n",
        "X_ols = XS_base.join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg').\\\n",
        "        join(X_vecs).join(X_company, rsuffix='cp').\\\n",
        "        join(X_dist, rsuffix='ds').join(X_mpaa).join(X_genre, rsuffix='gn').\\\n",
        "        join(X_cast, rsuffix='cs')\n",
        "\n",
        "ols = sm.OLS(y_ols, X_ols) \n",
        "reg_res = ols.fit().get_robustcov_results()\n",
        "\n",
        "loc_DFem = X_ols.columns.get_loc('D_Female')\n",
        "reg_budget_ols_results.update({'spec5': store_ols_results(reg_res,loc_DFem)})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK0tEu8tAtFu"
      },
      "source": [
        "### DML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbSg0aaFA-TU",
        "outputId": "48092b93-c590-40f2-b889-9efad3f5e4bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Features: 400\n"
          ]
        }
      ],
      "source": [
        "\n",
        "XB_full = XB_base.join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg').\\\n",
        "        join(X_vecs).join(X_company, rsuffix='cp').\\\n",
        "        join(X_dist, rsuffix='ds').join(X_mpaa).join(X_genre, rsuffix='gn')\n",
        "\n",
        "data_budget = XB_full.join(y_budget)\n",
        "y_budget_dml = data_budget['np.log(est_budget)']\n",
        "data_budget = data_budget.rename(columns={'np.log(est_budget)': 'log_budget'})\n",
        "x_cols = list(set(data_budget.columns.values) - {'D_Female','log_budget' })\n",
        "\n",
        "dml_data_budget = DoubleMLData(data_budget, y_col = 'log_budget', d_cols = 'D_Female',\n",
        "                        x_cols = x_cols)\n",
        "\n",
        "print(f'Number of Features: {len(x_cols)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "6jyvEqDRA-TX"
      },
      "outputs": [],
      "source": [
        "# Since tuning models in DML takes time, I defined the tuned versions from the previous runs\n",
        "ENet_tuned = ElasticNet(alpha=0.001, l1_ratio=0.01)\n",
        "\n",
        "RF_tuned = RandomForestRegressor(n_jobs = -1, n_estimators = 300, max_features = 'sqrt'\n",
        "                          , max_depth=40, min_samples_split= 4, random_state=seed)\n",
        "\n",
        "XGB_tuned = XGBRegressor(objective = \"reg:squarederror\", eta = 0.2,\n",
        "                        n_estimators =50, n_jobs=-1, max_depth= 10, random_state=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "20vAoPTUA-TX"
      },
      "outputs": [],
      "source": [
        "# # Random Forests\n",
        "# rfc_scores = cross_val_score(RF_tuned,XB_full, y_budget, n_jobs=-1, scoring = 'r2',\n",
        "#                              cv = ShuffleSplit(n_splits=3))\n",
        "# print(f'rfc_scores: {rfc_scores}')\n",
        "\n",
        "# # XGBoost: TFIDF Matrix\n",
        "# xgb_scores =  cross_val_score(XGB_tuned,XB_full, y_budget, n_jobs=-1, scoring = 'r2',\n",
        "#                               cv = ShuffleSplit(n_splits=3))\n",
        "# print(f'xgb_scores: {xgb_scores}')\n",
        "\n",
        "# # Elastic Net: \n",
        "# elnet_scores = cross_val_score(ENet_tuned,XB_full, y_budget, n_jobs=-1, scoring = 'r2',cv = ShuffleSplit(n_splits=5))\n",
        "# print(f'elnet_scores: {elnet_scores}')\n",
        "\n",
        "# # CV R2 Summary: RF roughly 0.40, XGB roughly 0.43, Elastic Net: roughly 0.55"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "Ozss_yGKA-TY"
      },
      "outputs": [],
      "source": [
        "# DML 1\n",
        "np.random.seed(seed)\n",
        "# learner_g = ElasticNet()\n",
        "learner_g = ENet_tuned\n",
        "learner_m = lgt_classifier\n",
        "ml_g = clone(learner_g)\n",
        "ml_m = clone(learner_m)\n",
        "param_grids = {'ml_g': {'alpha': [0.0001, 0.001, 0.1], 'l1_ratio': [ 0.01,0.25,0.5,0.75,0.99]},\n",
        "              'ml_m': lgt_params}\n",
        "dml_budget = DoubleMLPLR(dml_data_budget, ml_g, ml_m)\n",
        "# dml_budget.tune(param_grids, n_folds_tune=3, n_jobs_cv=-1)\n",
        "dml_budget.fit(n_jobs_cv=-1, store_predictions=True);\n",
        "\n",
        "# Store Coef and SE\n",
        "reg_budget_dml_results.update({'ElasticNet': store_dml_results(dml_budget)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6ogNhKoA-TZ",
        "outputId": "c748175a-ce75-4a7e-b0b1-060d821ccfeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: Learner ml_g was renamed to ml_l. Please adapt the key of param_grids accordingly. The provided param_grids for ml_g are set for ml_l. The redirection will be removed in a future version.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "# DML Random Forest\n",
        "np.random.seed(seed)\n",
        "learner_g = RandomForestRegressor(n_jobs = -1, n_estimators = 300,\n",
        "                                  max_features= 'sqrt')\n",
        "learner_g = RF_tuned\n",
        "learner_m = lgt_classifier\n",
        "ml_g = clone(learner_g)\n",
        "ml_m = clone(learner_m)\n",
        "\n",
        "param_grids = {'ml_g': {'max_depth': [ 20, 40, 80], 'min_samples_split': [4,8,16]},\n",
        "              'ml_m': lgt_params}\n",
        "\n",
        "dml_budget = DoubleMLPLR(dml_data_budget, ml_g, ml_m)\n",
        "dml_budget.tune(param_grids, n_folds_tune=3, n_jobs_cv=-1)\n",
        "dml_budget.fit(n_jobs_cv=-1, store_predictions=True);\n",
        "\n",
        "# Store Coef and SE\n",
        "reg_budget_dml_results.update({'RandomForest': store_dml_results(dml_budget)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "cDPTilZbA-Ta"
      },
      "outputs": [],
      "source": [
        "# DML XGBoost\n",
        "np.random.seed(seed)\n",
        "# learner_g =  XGBRegressor(objective = \"reg:squarederror\",\n",
        "#                         n_estimators =50, n_jobs=-1, random_state=seed)\n",
        "learner_g = XGB_tuned\n",
        "learner_m = lgt_classifier\n",
        "ml_g = clone(learner_g)\n",
        "ml_m = clone(learner_m)\n",
        "param_grids = {'ml_g': {'max_depth': [10, 20, 30], 'eta': [0.2, 0.4, 0.6]},\n",
        "              'ml_m': lgt_params}\n",
        "\n",
        "dml_budget = DoubleMLPLR(dml_data_budget, ml_g, ml_m)\n",
        "# dml_budget.tune(param_grids, n_folds_tune=3, n_jobs_cv=-1)\n",
        "dml_budget.fit(n_jobs_cv=-1, store_predictions=True);\n",
        "\n",
        "# Store Coef and SE\n",
        "reg_budget_dml_results.update({'XGBoost': store_dml_results(dml_budget)})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Winsorizred Regs"
      ],
      "metadata": {
        "id": "vVr-1stT2TNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q01_budget = y_budget['np.log(est_budget)'].quantile(.01)\n",
        "q99_budget = y_budget['np.log(est_budget)'].quantile(.99)\n",
        "\n",
        "keep_indx = y_budget.loc[((y_budget['np.log(est_budget)']>q01_budget) & \n",
        "          (y_budget['np.log(est_budget)']<q99_budget))].index.values\n",
        "\n",
        "y_budget_win = y_budget.iloc[y_budget.index.isin(keep_indx)]\n",
        "XB_base_win = XB_base.iloc[y_budget.index.isin(keep_indx)]"
      ],
      "metadata": {
        "id": "aGXFWqIq0iaz"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Winsorized Reg\n",
        "y_ols = y_budget_win.copy()\n",
        "X_ols = XB_base_win.join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg').\\\n",
        "        join(X_vecs).join(X_company, rsuffix='cp').\\\n",
        "        join(X_dist, rsuffix='ds').join(X_mpaa).join(X_genre, rsuffix='gn')\n",
        "\n",
        "ols = sm.OLS(y_ols, X_ols) \n",
        "reg_res = ols.fit().get_robustcov_results()\n",
        "\n",
        "loc_DFem = X_ols.columns.get_loc('D_Female')\n",
        "reg_budget_ols_results.update({'winsorized_reg': store_ols_results(reg_res,loc_DFem)})"
      ],
      "metadata": {
        "id": "_Yl89N630iaz"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quantile Regressions"
      ],
      "metadata": {
        "id": "ZVR3yK9W3Qax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yb_qreg = y_budget.copy()\n",
        "XB_qreg = XB_base.join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg').\\\n",
        "        join(X_vecs).join(X_company, rsuffix='cp').\\\n",
        "        join(X_dist, rsuffix='ds').join(X_mpaa).join(X_genre, rsuffix='gn')"
      ],
      "metadata": {
        "id": "Vgih8ZFc2VMZ"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Caution: Takes LONG to execute\n",
        "# qreg_model = sm.regression.quantile_regression.QuantReg(yb_qreg,XB_qreg)\n",
        "# quantiles = np.arange(0.1, 0.91,0.10)\n",
        "# qreg_results_budg = [qreg_fit(q) for q in quantiles]\n",
        "# df_qreg_res_budg = pd.DataFrame(qreg_results_budg, columns=[\"q\", \"coef\", \"se\", \"p-val\", \"lb\", \"ub\"])\n",
        "# df_qreg_res_budg.to_csv(results_dir + 'qreg_results_budget.csv')"
      ],
      "metadata": {
        "id": "EhYWaIz22VMa"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ti4mO-Tb9FiS"
      },
      "source": [
        "### MeToo Impact"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "HRJNUhfD9KZW"
      },
      "outputs": [],
      "source": [
        "# OLS\n",
        "# XS_base: X_base of the Sales specification\n",
        "y_budget, XB_me2 = dmatrices('np.log(est_budget) ~ D_Female + C(Year) + DFem_PMe2',\n",
        "                    data=df_boxoff_me2, return_type='dataframe')\n",
        "\n",
        "# OLS: Fully Saturated Model\n",
        "y_ols = y_budget.copy()\n",
        "X_ols = XB_me2.join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg').\\\n",
        "        join(X_vecs).join(X_company, rsuffix='cp').\\\n",
        "        join(X_dist, rsuffix='ds')\n",
        "\n",
        "ols = sm.OLS(y_ols, X_ols) \n",
        "reg_res = ols.fit().get_robustcov_results()\n",
        "\n",
        "loc_DFem = X_ols.columns.get_loc('D_Female')\n",
        "loc_DFem_pme2 = X_ols.columns.get_loc('DFem_PMe2')\n",
        "reg_budget_ols_results.update({'metoo': \n",
        "                      store_ols_results(reg_res,loc_DFem,loc_DFem_pme2,\n",
        "                                        post_me2=True)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "YWcewDF89KZY"
      },
      "outputs": [],
      "source": [
        "# DML\n",
        "data_budget_me2 = X_ols.join(y_budget)\n",
        "data_budget_me2 = data_budget_me2.rename(columns={'np.log(est_budget)': 'log_budget'})\n",
        "x_cols_me2 = list(set(X_ols.columns.values) - {'D_Female', 'DFem_PMe2'})\n",
        "\n",
        "dml_data_budget_me2 = DoubleMLData(data_budget_me2, y_col = 'log_budget', d_cols =\n",
        "                                 ['D_Female','DFem_PMe2'], x_cols = x_cols_me2)\n",
        "\n",
        "# Double ML:\n",
        "# DML ElasticNet\n",
        "learner_g = ENet_tuned\n",
        "learner_m = lgt_classifier\n",
        "ml_g = clone(learner_g)\n",
        "ml_m = clone(learner_m)\n",
        "dml_budget = DoubleMLPLR(dml_data_budget_me2, ml_g, ml_m)\n",
        "dml_budget.fit(n_jobs_cv=-1, store_predictions=True);\n",
        "reg_budget_dml_results.update({'metoo(ENet)': store_dml_results(dml_budget, \n",
        "                                                                   post_me2=True)})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oe9alJO7Nyu0"
      },
      "source": [
        "### Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "s7wLGWDlNyu2"
      },
      "outputs": [],
      "source": [
        "#Save Results\n",
        "reg_budget_results = {'OLS': reg_budget_ols_results, 'DML': reg_budget_dml_results}\n",
        "agg_outcomes_reg_results.update({'Budget': reg_budget_results})\n",
        "\n",
        "with open(results_dir + 'agg_outcomes_reg_results.json', 'w') as outfile:\n",
        "    json.dump(agg_outcomes_reg_results, outfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97lAA0GLNyu4",
        "outputId": "d39e178f-89b7-49de-eb8f-cad224922cbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ],
      "source": [
        "# Create DataFrame of the Results\n",
        "\n",
        "specs = list(reg_budget_ols_results.keys()) + list(reg_budget_dml_results.keys()) \n",
        "\n",
        "params_ols =  ['coef D_Female', 'se D_Female', 'p-val D_Female']\n",
        "params_dml =  ['coef D_Female', 'se D_Female', 'p-val D_Female']\n",
        "spec_ols = list(reg_budget_ols_results.keys() -{'metoo'})\n",
        "spec_dml = list(reg_budget_dml_results.keys() - {'metoo(ENet)'} )\n",
        "\n",
        "data_ols = [[reg_budget_ols_results[spec][p][0] for p in params_ols] for spec in spec_ols]\n",
        "data_r2 = [[reg_budget_ols_results[spec][p] for p in ['R2', 'N Obs']] for spec in spec_ols]\n",
        "data_ols = [data_ols[r] + data_r2[r] for r in range(len(data_ols))]\n",
        "\n",
        "data_dml = [[reg_budget_dml_results[spec][p][0] for p in params_dml] for spec in spec_dml]\n",
        "\n",
        "\n",
        "data_DFem = np.asarray(data_ols + data_dml )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "4LOjlJ1iNyu6"
      },
      "outputs": [],
      "source": [
        "# Cast the results in tables\n",
        "table_ols_budget = pd.DataFrame(np.asarray(data_ols).T, columns= spec_ols,\n",
        "                               index = ['coef', 'SE', 'P-Val', 'R2', 'N'])\n",
        "\n",
        "table_dml_budget = pd.DataFrame(np.asarray(data_dml).T, columns= spec_dml,\n",
        "                               index = ['coef', 'SE', 'P-Val'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wgEN_eXRA2D"
      },
      "source": [
        "## Metascore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "K0QReCIjRaVa"
      },
      "outputs": [],
      "source": [
        "# Temporarily Storing Results in dicts\n",
        "reg_meta_dml_results={}\n",
        "reg_meta_ols_results = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "CAFcC8tARaVe"
      },
      "outputs": [],
      "source": [
        "df_scores = df_movies.loc[~((df_movies['metascore'].isna()) |\n",
        "                            (df_movies['userscore'].isna()))].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7Xdq-4Thnt9"
      },
      "source": [
        "### OLS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "SAUAu_LpRaVh"
      },
      "outputs": [],
      "source": [
        "# XS_base: X_base of the meta specification\n",
        "y_meta, XM_base = dmatrices('metascore ~  D_Female + C(Year)',\n",
        "                    data=df_scores, return_type='dataframe')\n",
        "\n",
        "# XGB throws error if '[]' are in columns names:\n",
        "year_cols = dict(zip([f'C(Year)[T.{y}]' for y in range(1991,2022)],\n",
        "                     [f'Year({y})' for y in range(1991,2022)] ))\n",
        "XM_base = XM_base.rename(columns = year_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "nXJl4Cd3RaVi"
      },
      "outputs": [],
      "source": [
        "# OLS meta Baseline\n",
        "y_ols = y_meta.copy()\n",
        "X_ols = XM_base.copy()\n",
        "ols = sm.OLS(y_ols, X_ols) \n",
        "reg_res = ols.fit().get_robustcov_results()\n",
        "\n",
        "loc_DFem = X_ols.columns.get_loc('D_Female')\n",
        "reg_meta_ols_results.update({'Base': store_ols_results(reg_res,loc_DFem)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "ezt1WJEURaVj"
      },
      "outputs": [],
      "source": [
        "#Countries\n",
        "df_scores['country_list'] = df_scores['country'].map(lambda x: re.sub(' ','',x)).\\\n",
        "                        map(lambda x: x.split(','))\n",
        "\n",
        "X_country = pd.DataFrame(mlb.fit_transform(df_scores['country_list']),\n",
        "             columns=mlb.classes_, index=df_scores.index)\n",
        "\n",
        "X_country = X_country[X_country.columns[X_country.sum()>=10]]\n",
        "\n",
        "#Language\n",
        "df_scores['lang_list'] = df_scores['language'].map(lambda x: re.sub(' ','',x)).\\\n",
        "                        map(lambda x: x.split(','))\n",
        "X_lang = pd.DataFrame(mlb.fit_transform(df_scores['lang_list']),\n",
        "             columns=mlb.classes_, index=df_scores.index)\n",
        "X_lang = X_lang[X_lang.columns[X_lang.sum()>=10]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "HQFWw4xeRaVk"
      },
      "outputs": [],
      "source": [
        "# OLS Country and Language FE: Spec2\n",
        "y_ols = y_meta.copy()\n",
        "X_ols = XM_base.join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg')\n",
        "\n",
        "ols = sm.OLS(y_ols, X_ols) \n",
        "reg_res = ols.fit().get_robustcov_results()\n",
        "\n",
        "loc_DFem = X_ols.columns.get_loc('D_Female')\n",
        "reg_meta_ols_results.update({'spec2': store_ols_results(reg_res,loc_DFem)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "-iSSGA-XRaVl"
      },
      "outputs": [],
      "source": [
        "# Plot Truncated SVD Vectors\n",
        "plot_vectors = [f'plot_vec{i}' for i in range(100)]\n",
        "X_vecs = df_scores[plot_vectors]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "4Fyf5WfSRaVm"
      },
      "outputs": [],
      "source": [
        "# spec3 = spec2 + Plot Vectors FE\n",
        "y_ols = y_meta.copy()\n",
        "X_ols = XM_base.join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg').join(X_vecs)\n",
        "\n",
        "ols = sm.OLS(y_ols, X_ols) \n",
        "reg_res = ols.fit().get_robustcov_results()\n",
        "\n",
        "loc_DFem = X_ols.columns.get_loc('D_Female')\n",
        "reg_meta_ols_results.update({'spec3': store_ols_results(reg_res,loc_DFem)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "zXS5Pz95RaVn"
      },
      "outputs": [],
      "source": [
        "# Companies with at least 10 movies\n",
        "X_company = pd.get_dummies(df_scores['company'])\n",
        "X_company = X_company[X_company.columns[X_company.sum()>=10]]\n",
        "\n",
        "# Distributors with at least 10 movies\n",
        "X_dist = pd.get_dummies(df_scores['Distributor'])\n",
        "X_dist = X_dist[X_dist.columns[X_dist.sum()>=10]]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "QuKihuEfRaVo"
      },
      "outputs": [],
      "source": [
        "# spec4:  spec3 + company and distributor FE\n",
        "y_ols = y_meta.copy()\n",
        "X_ols = XM_base.join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg').\\\n",
        "        join(X_vecs).join(X_company, rsuffix='cp').\\\n",
        "        join(X_dist, rsuffix='ds')\n",
        "\n",
        "ols = sm.OLS(y_ols, X_ols) \n",
        "reg_res = ols.fit().get_robustcov_results()\n",
        "\n",
        "loc_DFem = X_ols.columns.get_loc('D_Female')\n",
        "reg_meta_ols_results.update({'spec4': store_ols_results(reg_res,loc_DFem)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "2Yl5n6GlRaVp"
      },
      "outputs": [],
      "source": [
        "#Cast\n",
        "X_cast = pd.DataFrame(mlb.fit_transform(df_scores['cast']),columns=mlb.classes_, index=df_scores.index)\n",
        "# Keeping actors whose names showed up at least 10 times\n",
        "X_cast = X_cast[X_cast.columns[X_cast.sum()>=10]]\n",
        "\n",
        "# Age Ratings Categories\n",
        "X_mpaa = df_scores[['rated_R','rated_PG', 'rated_PG13', 'rated_TVMA', 'rated_TV14']]\n",
        "\n",
        "# Genres\n",
        "X_genre = df_scores[genres]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "vSqDNYnURaVq"
      },
      "outputs": [],
      "source": [
        "# spec5:  spec4 + cast + age ratigns, mpaa, and genres\n",
        "y_ols = y_meta.copy()\n",
        "X_ols = XM_base.join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg').\\\n",
        "        join(X_vecs).join(X_cast, rsuffix='cs').join(X_company, rsuffix='cp').\\\n",
        "        join(X_dist, rsuffix='ds').join(X_mpaa).join(X_genre, rsuffix='gn')\n",
        "\n",
        "ols = sm.OLS(y_ols, X_ols) \n",
        "reg_res = ols.fit().get_robustcov_results()\n",
        "\n",
        "loc_DFem = X_ols.columns.get_loc('D_Female')\n",
        "reg_meta_ols_results.update({'spec5': store_ols_results(reg_res,loc_DFem)})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CILI02iPRaVv"
      },
      "source": [
        "### DML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g2d71O-RaVw",
        "outputId": "cb5513f0-6480-40dd-bb7a-da87bb3f37e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Features: 1224\n"
          ]
        }
      ],
      "source": [
        "\n",
        "XM_full = XM_base.join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg').\\\n",
        "        join(X_vecs).join(X_cast, rsuffix='cs').join(X_company, rsuffix='cp').\\\n",
        "        join(X_dist, rsuffix='ds').join(X_mpaa).join(X_genre, rsuffix='gn')\n",
        "\n",
        "data_meta = XM_full.join(y_meta)\n",
        "y_meta = data_meta['metascore']\n",
        "x_cols = list(set(data_meta.columns.values) - {'D_Female','metascore' })\n",
        "\n",
        "dml_data_meta = DoubleMLData(data_meta, y_col = 'metascore', d_cols = 'D_Female',\n",
        "                        x_cols = x_cols)\n",
        "\n",
        "print(f'Number of Features: {len(x_cols)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "_aPJc_0eRaVx"
      },
      "outputs": [],
      "source": [
        "# Tuning Classifier (learner_m):\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Selection Stage\n",
        "d_fem = XM_full['D_Female']\n",
        "X_cls = XM_full.drop(columns=['D_Female'])\n",
        "\n",
        "# # Logit\n",
        "# param_grid = {'penalty': ['l2', 'l1'], \n",
        "#               'C': [ 1e5,1e6, 1e7, 1e8, 1e9]}\n",
        "# lgt = LogisticRegression(solver='liblinear', random_state=seed)\n",
        "# clf = GridSearchCV(lgt, param_grid, scoring='f1',cv = ShuffleSplit(n_splits=5,random_state=seed))\n",
        "# clf.fit(X_cls, d_fem)\n",
        "# lgt_classifier = clf.best_estimator_\n",
        "# lgt_params = {'C': [clf.best_params_['C']], 'penalty': [clf.best_params_['penalty']]}\n",
        "\n",
        "# # F1 Test Scores are about 0.20\n",
        "# lgt_test_scores = cross_val_score(lgt_classifier,X_cls, d_fem, n_jobs=-1, scoring = 'f1',cv = ShuffleSplit(n_splits=5))\n",
        "# print(f'lgt_scores: {lgt_test_scores}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "uc6Lf_jBRaVz"
      },
      "outputs": [],
      "source": [
        "# Since tuning models in DML takes time, I defined the tuned versions from the previous runs\n",
        "lgt_classifier = LogisticRegression(solver='liblinear', penalty='l2', C=1e8,  random_state=seed)\n",
        "\n",
        "ENet_tuned = ElasticNet(alpha=0.001, l1_ratio=0.01)\n",
        "\n",
        "RF_tuned = RandomForestRegressor(n_jobs = -1, n_estimators = 300, max_features = 'sqrt'\n",
        "                          , max_depth=40, min_samples_split= 8, random_state=seed)\n",
        "\n",
        "XGB_tuned = XGBRegressor(objective = \"reg:squarederror\", eta = 0.2,\n",
        "                        n_estimators =50, n_jobs=-1, max_depth= 10, random_state=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "Iwgf6NiXRaV0"
      },
      "outputs": [],
      "source": [
        "# # Random Forests\n",
        "# rfc_scores = cross_val_score(RF_tuned,XM_full, y_meta, n_jobs=-1, scoring = 'r2',\n",
        "#                              cv = ShuffleSplit(n_splits=3))\n",
        "# print(f'rfc_scores: {rfc_scores}')\n",
        "\n",
        "# # XGBoost: TFIDF Matrix\n",
        "# xgb_scores =  cross_val_score(XGB_tuned,XM_full, y_meta, n_jobs=-1, scoring = 'r2',\n",
        "#                               cv = ShuffleSplit(n_splits=3))\n",
        "# print(f'xgb_scores: {xgb_scores}')\n",
        "\n",
        "# # Elastic Net: \n",
        "# elnet_scores = cross_val_score(ENet_tuned,XM_full, y_meta, n_jobs=-1, scoring = 'r2',cv = ShuffleSplit(n_splits=5))\n",
        "# print(f'elnet_scores: {elnet_scores}')\n",
        "\n",
        "# # CV R2 Summary: RF roughly 0.45, XGB roughly 0.50, Elastic Net: roughly 0.63"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "t_vVZpVXRaV2"
      },
      "outputs": [],
      "source": [
        "# DML 1\n",
        "np.random.seed(seed)\n",
        "# learner_g = ElasticNet()\n",
        "learner_g = ENet_tuned\n",
        "learner_m = lgt_classifier\n",
        "ml_g = clone(learner_g)\n",
        "ml_m = clone(learner_m)\n",
        "param_grids = {'ml_g': {'alpha': [0.0001, 0.001, 0.1], 'l1_ratio': [ 0.01,0.25,0.5,0.75,0.99]},\n",
        "              'ml_m': lgt_params}\n",
        "dml_meta = DoubleMLPLR(dml_data_meta, ml_g, ml_m)\n",
        "# dml_meta.tune(param_grids, n_folds_tune=3, n_jobs_cv=-1)\n",
        "dml_meta.fit(n_jobs_cv=-1, store_predictions=True);\n",
        "\n",
        "# Store Coef and SE\n",
        "reg_meta_dml_results.update({'ElasticNet': store_dml_results(dml_meta)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "QY08JbE_RaV3"
      },
      "outputs": [],
      "source": [
        "# DML Random Forest\n",
        "np.random.seed(seed)\n",
        "# learner_g = RandomForestRegressor(n_jobs = -1, n_estimators = 300,\n",
        "#                                   max_features= 'sqrt')\n",
        "learner_g = RF_tuned\n",
        "learner_m = lgt_classifier\n",
        "ml_g = clone(learner_g)\n",
        "ml_m = clone(learner_m)\n",
        "\n",
        "param_grids = {'ml_g': {'max_depth': [ 20, 40, 80], 'min_samples_split': [4,8,16]},\n",
        "              'ml_m': lgt_params}\n",
        "\n",
        "dml_meta = DoubleMLPLR(dml_data_meta, ml_g, ml_m)\n",
        "# dml_meta.tune(param_grids, n_folds_tune=3, n_jobs_cv=-1)\n",
        "dml_meta.fit(n_jobs_cv=-1, store_predictions=True);\n",
        "\n",
        "# Store Coef and SE\n",
        "reg_meta_dml_results.update({'RandomForest': store_dml_results(dml_meta)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "np4WmqdkRaV4",
        "outputId": "1000017f-9b8a-4f40-89cc-378d6a6b75e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:703: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ]
        }
      ],
      "source": [
        "# DML XGBoost\n",
        "np.random.seed(seed)\n",
        "# learner_g =  XGBRegressor(objective = \"reg:squarederror\",\n",
        "#                         n_estimators =50, n_jobs=-1, random_state=seed)\n",
        "learner_g = XGB_tuned\n",
        "learner_m = lgt_classifier\n",
        "ml_g = clone(learner_g)\n",
        "ml_m = clone(learner_m)\n",
        "param_grids = {'ml_g': {'max_depth': [10, 20, 30], 'eta': [0.2, 0.4, 0.6]},\n",
        "              'ml_m': lgt_params}\n",
        "\n",
        "dml_meta = DoubleMLPLR(dml_data_meta, ml_g, ml_m)\n",
        "# dml_meta.tune(param_grids, n_folds_tune=3, n_jobs_cv=-1)\n",
        "dml_meta.fit(n_jobs_cv=-1, store_predictions=True);\n",
        "\n",
        "# Store Coef and SE\n",
        "reg_meta_dml_results.update({'XGBoost': store_dml_results(dml_meta)})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_lNWWpxRGUX"
      },
      "source": [
        "### MeToo Impact"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "lLwcrkW1SAny"
      },
      "outputs": [],
      "source": [
        "df_scores_me2= df_scores.copy()\n",
        "#post me too >=2018\n",
        "df_scores_me2['DFem_PMe2'] = np.where(((df_scores_me2['D_Female']==1) & (df_scores_me2['Year']>2017)), 1,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "Uk9sjURVRGUZ"
      },
      "outputs": [],
      "source": [
        "# OLS\n",
        "# XS_base: X_base of the Sales specification\n",
        "y_meta, XM_me2 = dmatrices('metascore ~ D_Female + C(Year) + DFem_PMe2',\n",
        "                    data=df_scores_me2, return_type='dataframe')\n",
        "\n",
        "# OLS: Fully Saturated Model\n",
        "y_ols = y_meta.copy()\n",
        "X_ols = XM_me2.join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg').\\\n",
        "        join(X_vecs).join(X_company, rsuffix='cp').\\\n",
        "        join(X_dist, rsuffix='ds')\n",
        "\n",
        "ols = sm.OLS(y_ols, X_ols) \n",
        "reg_res = ols.fit().get_robustcov_results()\n",
        "\n",
        "loc_DFem = X_ols.columns.get_loc('D_Female')\n",
        "loc_DFem_pme2 = X_ols.columns.get_loc('DFem_PMe2')\n",
        "reg_meta_ols_results.update({'metoo': \n",
        "                      store_ols_results(reg_res,loc_DFem,loc_DFem_pme2,\n",
        "                                        post_me2=True)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "8sviNpfDRGUa"
      },
      "outputs": [],
      "source": [
        "# DML\n",
        "data_meta_me2 = X_ols.join(y_meta)\n",
        "x_cols_me2 = list(set(X_ols.columns.values) - {'D_Female', 'DFem_PMe2'})\n",
        "\n",
        "dml_data_meta_me2 = DoubleMLData(data_meta_me2, y_col = 'metascore', d_cols =\n",
        "                                 ['D_Female','DFem_PMe2'], x_cols = x_cols_me2)\n",
        "\n",
        "# Double ML:\n",
        "# DML ElasticNet\n",
        "learner_g = ENet_tuned\n",
        "learner_m = lgt_classifier\n",
        "ml_g = clone(learner_g)\n",
        "ml_m = clone(learner_m)\n",
        "dml_meta = DoubleMLPLR(dml_data_meta_me2, ml_g, ml_m)\n",
        "dml_meta.fit(n_jobs_cv=-1, store_predictions=True);\n",
        "reg_meta_dml_results.update({'metoo(ENet)': store_dml_results(dml_meta, \n",
        "                                                                   post_me2=True)})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoSpfhQCRGUb"
      },
      "source": [
        "### Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "3a5QHnfTRGUb"
      },
      "outputs": [],
      "source": [
        "#Save Results\n",
        "reg_meta_results = {'OLS': reg_meta_ols_results, 'DML': reg_meta_dml_results}\n",
        "agg_outcomes_reg_results.update({'Meta': reg_meta_results})\n",
        "\n",
        "with open(results_dir + 'agg_outcomes_reg_results.json', 'w') as outfile:\n",
        "    json.dump(agg_outcomes_reg_results, outfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2X3Zm-pRGUc",
        "outputId": "c0ce9885-ac88-41e7-bba3-bdacf68f5c92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ],
      "source": [
        "# Create DataFrame of the Results\n",
        "\n",
        "specs = list(reg_meta_ols_results.keys()) + list(reg_meta_dml_results.keys()) \n",
        "\n",
        "params_ols =  ['coef D_Female', 'se D_Female', 'p-val D_Female']\n",
        "params_dml =  ['coef D_Female', 'se D_Female', 'p-val D_Female']\n",
        "spec_ols = list(reg_meta_ols_results.keys() -{'metoo'})\n",
        "spec_dml = list(reg_meta_dml_results.keys() - {'metoo(ENet)'} )\n",
        "\n",
        "data_ols = [[reg_meta_ols_results[spec][p][0] for p in params_ols] for spec in spec_ols]\n",
        "data_r2 = [[reg_meta_ols_results[spec][p] for p in ['R2', 'N Obs']] for spec in spec_ols]\n",
        "data_ols = [data_ols[r] + data_r2[r] for r in range(len(data_ols))]\n",
        "\n",
        "data_dml = [[reg_meta_dml_results[spec][p][0] for p in params_dml] for spec in spec_dml]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data_DFem = np.asarray(data_ols + data_dml )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "m1W8iWLLRGUd"
      },
      "outputs": [],
      "source": [
        "# Cast  the results in tables\n",
        "table_ols_meta = pd.DataFrame(np.asarray(data_ols).T, columns= spec_ols,\n",
        "                               index = ['coef', 'SE', 'P-Val', 'R2', 'N'])\n",
        "\n",
        "table_dml_meta = pd.DataFrame(np.asarray(data_dml).T, columns= spec_dml,\n",
        "                               index = ['coef', 'SE', 'P-Val'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCLDSRU6h5NC"
      },
      "source": [
        "## Userscore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "nbqS8CH3h5ND"
      },
      "outputs": [],
      "source": [
        "# Temporarily Storing Results in dicts\n",
        "reg_user_dml_results={}\n",
        "reg_user_ols_results = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfAXjnXYh5NE"
      },
      "source": [
        "### OLS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "w6_w7eIjh5NF"
      },
      "outputs": [],
      "source": [
        "# XS_base: X_base of the user specification\n",
        "y_user, XU_base = dmatrices('userscore ~  D_Female + C(Year)',\n",
        "                    data=df_scores, return_type='dataframe')\n",
        "\n",
        "# XGB throws error if '[]' are in columns names:\n",
        "year_cols = dict(zip([f'C(Year)[T.{y}]' for y in range(1991,2022)],\n",
        "                     [f'Year({y})' for y in range(1991,2022)] ))\n",
        "XU_base = XU_base.rename(columns = year_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "v43tpMdwh5NF"
      },
      "outputs": [],
      "source": [
        "# OLS user Baseline\n",
        "y_ols = y_user.copy()\n",
        "X_ols = XU_base.copy()\n",
        "ols = sm.OLS(y_ols, X_ols) \n",
        "reg_res = ols.fit().get_robustcov_results()\n",
        "\n",
        "loc_DFem = X_ols.columns.get_loc('D_Female')\n",
        "reg_user_ols_results.update({'Base': store_ols_results(reg_res,loc_DFem)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "3Q9ptrmZh5NG"
      },
      "outputs": [],
      "source": [
        "#Countries\n",
        "df_scores['country_list'] = df_scores['country'].map(lambda x: re.sub(' ','',x)).\\\n",
        "                        map(lambda x: x.split(','))\n",
        "\n",
        "X_country = pd.DataFrame(mlb.fit_transform(df_scores['country_list']),\n",
        "             columns=mlb.classes_, index=df_scores.index)\n",
        "\n",
        "X_country = X_country[X_country.columns[X_country.sum()>=10]]\n",
        "\n",
        "#Language\n",
        "df_scores['lang_list'] = df_scores['language'].map(lambda x: re.sub(' ','',x)).\\\n",
        "                        map(lambda x: x.split(','))\n",
        "X_lang = pd.DataFrame(mlb.fit_transform(df_scores['lang_list']),\n",
        "             columns=mlb.classes_, index=df_scores.index)\n",
        "X_lang = X_lang[X_lang.columns[X_lang.sum()>=10]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "YsuPvY0Kh5NH"
      },
      "outputs": [],
      "source": [
        "# OLS Country and Language FE: Spec2\n",
        "y_ols = y_user.copy()\n",
        "X_ols = XU_base.join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg')\n",
        "\n",
        "ols = sm.OLS(y_ols, X_ols) \n",
        "reg_res = ols.fit().get_robustcov_results()\n",
        "\n",
        "loc_DFem = X_ols.columns.get_loc('D_Female')\n",
        "reg_user_ols_results.update({'spec2': store_ols_results(reg_res,loc_DFem)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "rE3GxkuUh5NH"
      },
      "outputs": [],
      "source": [
        "# Plot Truncated SVD Vectors\n",
        "plot_vectors = [f'plot_vec{i}' for i in range(100)]\n",
        "X_vecs = df_scores[plot_vectors]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "V_CysInwh5NI"
      },
      "outputs": [],
      "source": [
        "# spec3 = spec2 + Plot Vectors FE\n",
        "y_ols = y_user.copy()\n",
        "X_ols = XU_base.join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg').join(X_vecs)\n",
        "\n",
        "ols = sm.OLS(y_ols, X_ols) \n",
        "reg_res = ols.fit().get_robustcov_results()\n",
        "\n",
        "loc_DFem = X_ols.columns.get_loc('D_Female')\n",
        "reg_user_ols_results.update({'spec3': store_ols_results(reg_res,loc_DFem)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "nrk37t-Wh5NI"
      },
      "outputs": [],
      "source": [
        "# Companies with at least 10 movies\n",
        "X_company = pd.get_dummies(df_scores['company'])\n",
        "X_company = X_company[X_company.columns[X_company.sum()>=10]]\n",
        "\n",
        "# Distributors with at least 10 movies\n",
        "X_dist = pd.get_dummies(df_scores['Distributor'])\n",
        "X_dist = X_dist[X_dist.columns[X_dist.sum()>=10]]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "PCq8cVf1h5NJ"
      },
      "outputs": [],
      "source": [
        "# spec4:  spec3 + company and distributor FE\n",
        "y_ols = y_user.copy()\n",
        "X_ols = XU_base.join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg').\\\n",
        "        join(X_vecs).join(X_company, rsuffix='cp').\\\n",
        "        join(X_dist, rsuffix='ds')\n",
        "\n",
        "ols = sm.OLS(y_ols, X_ols) \n",
        "reg_res = ols.fit().get_robustcov_results()\n",
        "\n",
        "loc_DFem = X_ols.columns.get_loc('D_Female')\n",
        "reg_user_ols_results.update({'spec4': store_ols_results(reg_res,loc_DFem)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "vQORbdg4h5NK"
      },
      "outputs": [],
      "source": [
        "#Cast\n",
        "X_cast = pd.DataFrame(mlb.fit_transform(df_scores['cast']),columns=mlb.classes_, index=df_scores.index)\n",
        "# Keeping actors whose names showed up at least 10 times\n",
        "X_cast = X_cast[X_cast.columns[X_cast.sum()>=10]]\n",
        "\n",
        "\n",
        "# Age Ratings Categories\n",
        "X_mpaa = df_scores[['rated_R','rated_PG', 'rated_PG13', 'rated_TVMA', 'rated_TV14']]\n",
        "\n",
        "# Genres\n",
        "X_genre = df_scores[genres]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "4vcAlKiWh5NK"
      },
      "outputs": [],
      "source": [
        "# spec5:  spec4 + cast + age ratigns, mpaa, and genres\n",
        "y_ols = y_user.copy()\n",
        "X_ols = XU_base.join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg').\\\n",
        "        join(X_vecs).join(X_cast, rsuffix='cs').join(X_company, rsuffix='cp').\\\n",
        "        join(X_dist, rsuffix='ds').join(X_mpaa).join(X_genre, rsuffix='gn')\n",
        "\n",
        "ols = sm.OLS(y_ols, X_ols) \n",
        "reg_res = ols.fit().get_robustcov_results()\n",
        "\n",
        "loc_DFem = X_ols.columns.get_loc('D_Female')\n",
        "reg_user_ols_results.update({'spec5': store_ols_results(reg_res,loc_DFem)})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYsaZYreh5NM"
      },
      "source": [
        "### DML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoQKw7Qyh5NN",
        "outputId": "2a59297b-bb4c-4de9-f5cb-a24c1a22b010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Features: 1224\n"
          ]
        }
      ],
      "source": [
        "\n",
        "XU_full = XU_base.join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg').\\\n",
        "        join(X_vecs).join(X_cast, rsuffix='cs').join(X_company, rsuffix='cp').\\\n",
        "        join(X_dist, rsuffix='ds').join(X_mpaa).join(X_genre, rsuffix='gn')\n",
        "\n",
        "data_user = XU_full.join(y_user)\n",
        "y_user = data_user['userscore']\n",
        "x_cols = list(set(data_user.columns.values) - {'D_Female','userscore' })\n",
        "\n",
        "dml_data_user = DoubleMLData(data_user, y_col = 'userscore', d_cols = 'D_Female',\n",
        "                        x_cols = x_cols)\n",
        "\n",
        "print(f'Number of Features: {len(x_cols)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "A3Fvydffh5NO"
      },
      "outputs": [],
      "source": [
        "# Logit Classfier from the Previous part still applies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "8uNlugD8h5NP"
      },
      "outputs": [],
      "source": [
        "# Since tuning models in DML takes time, I defined the tuned versions from the previous runs\n",
        "lgt_classifier = LogisticRegression(solver='liblinear', penalty='l2', C=1e8,  random_state=seed)\n",
        "\n",
        "ENet_tuned = ElasticNet(alpha=0.001, l1_ratio=0.01)\n",
        "\n",
        "RF_tuned = RandomForestRegressor(n_jobs = -1, n_estimators = 300, max_features = 'sqrt'\n",
        "                          , max_depth=40, min_samples_split= 4, random_state=seed)\n",
        "\n",
        "XGB_tuned = XGBRegressor(objective = \"reg:squarederror\", eta = 0.2,\n",
        "                        n_estimators =50, n_jobs=-1, max_depth= 10, random_state=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "FM6l9c5jh5NP"
      },
      "outputs": [],
      "source": [
        "# # Random Forests\n",
        "# rfc_scores = cross_val_score(RF_tuned,XU_full, y_user, n_jobs=-1, scoring = 'r2',\n",
        "#                              cv = ShuffleSplit(n_splits=3))\n",
        "# print(f'rfc_scores: {rfc_scores}')\n",
        "\n",
        "# # XGBoost: TFIDF Matrix\n",
        "# xgb_scores =  cross_val_score(XGB_tuned,XU_full, y_user, n_jobs=-1, scoring = 'r2',\n",
        "#                               cv = ShuffleSplit(n_splits=3))\n",
        "# print(f'xgb_scores: {xgb_scores}')\n",
        "\n",
        "# # Elastic Net: \n",
        "# elnet_scores = cross_val_score(ENet_tuned,XU_full, y_user, n_jobs=-1, scoring = 'r2',cv = ShuffleSplit(n_splits=5))\n",
        "# print(f'elnet_scores: {elnet_scores}')\n",
        "\n",
        "# # CV R2 Summary: RF roughly 0.45, XGB roughly 0.50, Elastic Net: roughly 0.63"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "1shrE0Olh5NQ"
      },
      "outputs": [],
      "source": [
        "# DML 1\n",
        "np.random.seed(seed)\n",
        "# learner_g = ElasticNet()\n",
        "learner_g = ENet_tuned\n",
        "learner_m = lgt_classifier\n",
        "ml_g = clone(learner_g)\n",
        "ml_m = clone(learner_m)\n",
        "param_grids = {'ml_g': {'alpha': [0.0001, 0.001, 0.1], 'l1_ratio': [ 0.01,0.25,0.5,0.75,0.99]},\n",
        "              'ml_m': lgt_params}\n",
        "dml_user = DoubleMLPLR(dml_data_user, ml_g, ml_m)\n",
        "# dml_user.tune(param_grids, n_folds_tune=3, n_jobs_cv=-1)\n",
        "dml_user.fit(n_jobs_cv=-1, store_predictions=True);\n",
        "\n",
        "# Store Coef and SE\n",
        "reg_user_dml_results.update({'ElasticNet': store_dml_results(dml_user)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "mD7V6iiEh5NR"
      },
      "outputs": [],
      "source": [
        "# DML Random Forest\n",
        "np.random.seed(seed)\n",
        "# learner_g = RandomForestRegressor(n_jobs = -1, n_estimators = 300,\n",
        "#                                   max_features= 'sqrt')\n",
        "learner_g = RF_tuned\n",
        "learner_m = lgt_classifier\n",
        "ml_g = clone(learner_g)\n",
        "ml_m = clone(learner_m)\n",
        "\n",
        "param_grids = {'ml_g': {'max_depth': [ 20, 40, 80], 'min_samples_split': [4,8,16]},\n",
        "              'ml_m': lgt_params}\n",
        "\n",
        "dml_user = DoubleMLPLR(dml_data_user, ml_g, ml_m)\n",
        "# dml_user.tune(param_grids, n_folds_tune=3, n_jobs_cv=-1)\n",
        "dml_user.fit(n_jobs_cv=-1, store_predictions=True);\n",
        "\n",
        "# Store Coef and SE\n",
        "reg_user_dml_results.update({'RandomForest': store_dml_results(dml_user)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "EzEruo1Oh5NS"
      },
      "outputs": [],
      "source": [
        "# DML XGBoost\n",
        "np.random.seed(seed)\n",
        "# learner_g =  XGBRegressor(objective = \"reg:squarederror\",\n",
        "#                         n_estimators =50, n_jobs=-1, random_state=seed)\n",
        "learner_g = XGB_tuned\n",
        "learner_m = lgt_classifier\n",
        "ml_g = clone(learner_g)\n",
        "ml_m = clone(learner_m)\n",
        "param_grids = {'ml_g': {'max_depth': [10, 20, 30], 'eta': [0.2, 0.4, 0.6]},\n",
        "              'ml_m': lgt_params}\n",
        "\n",
        "dml_user = DoubleMLPLR(dml_data_user, ml_g, ml_m)\n",
        "# dml_user.tune(param_grids, n_folds_tune=3, n_jobs_cv=-1)\n",
        "dml_user.fit(n_jobs_cv=-1, store_predictions=True);\n",
        "\n",
        "# Store Coef and SE\n",
        "reg_user_dml_results.update({'XGBoost': store_dml_results(dml_user)})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYxdw9hQW97Q"
      },
      "source": [
        "### MeToo Impact"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "4GnQ9DUtW97T"
      },
      "outputs": [],
      "source": [
        "# OLS\n",
        "# XS_base: X_base of the Sales specification\n",
        "y_user, XU_me2 = dmatrices('userscore ~ D_Female + C(Year) + DFem_PMe2',\n",
        "                    data=df_scores_me2, return_type='dataframe')\n",
        "\n",
        "# OLS: Fully Saturated Model\n",
        "y_ols = y_user.copy()\n",
        "X_ols = XM_me2.join(X_country, rsuffix='cn').join(X_lang, rsuffix='lg').\\\n",
        "        join(X_vecs).join(X_company, rsuffix='cp').\\\n",
        "        join(X_dist, rsuffix='ds')\n",
        "\n",
        "ols = sm.OLS(y_ols, X_ols) \n",
        "reg_res = ols.fit().get_robustcov_results()\n",
        "\n",
        "loc_DFem = X_ols.columns.get_loc('D_Female')\n",
        "loc_DFem_pme2 = X_ols.columns.get_loc('DFem_PMe2')\n",
        "reg_user_ols_results.update({'metoo': \n",
        "                      store_ols_results(reg_res,loc_DFem,loc_DFem_pme2,\n",
        "                                        post_me2=True)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "Z6LUh4H3W97V"
      },
      "outputs": [],
      "source": [
        "# DML\n",
        "data_user_me2 = X_ols.join(y_user)\n",
        "x_cols_me2 = list(set(X_ols.columns.values) - {'D_Female', 'DFem_PMe2'})\n",
        "\n",
        "dml_data_user_me2 = DoubleMLData(data_user_me2, y_col = 'userscore', d_cols =\n",
        "                                 ['D_Female','DFem_PMe2'], x_cols = x_cols_me2)\n",
        "\n",
        "# Double ML:\n",
        "# DML ElasticNet\n",
        "learner_g = ENet_tuned\n",
        "learner_m = lgt_classifier\n",
        "ml_g = clone(learner_g)\n",
        "ml_m = clone(learner_m)\n",
        "dml_user = DoubleMLPLR(dml_data_user_me2, ml_g, ml_m)\n",
        "dml_user.fit(n_jobs_cv=-1, store_predictions=True);\n",
        "reg_user_dml_results.update({'metoo(ENet)': store_dml_results(dml_user, \n",
        "                                                                   post_me2=True)})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnZkgvFnW97W"
      },
      "source": [
        "### Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "FeRTRYqNW97X"
      },
      "outputs": [],
      "source": [
        "#Save Results\n",
        "reg_user_results = {'OLS': reg_user_ols_results, 'DML': reg_user_dml_results}\n",
        "agg_outcomes_reg_results.update({'User': reg_user_results})\n",
        "\n",
        "with open(results_dir + 'agg_outcomes_reg_results.json', 'w') as outfile:\n",
        "    json.dump(agg_outcomes_reg_results, outfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTsEwkcCW97Y",
        "outputId": "673fcc70-7968-4dcf-c8d8-53afdf45af71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ],
      "source": [
        "# Create DataFrame of the Results\n",
        "\n",
        "specs = list(reg_user_ols_results.keys()) + list(reg_user_dml_results.keys()) \n",
        "\n",
        "params_ols =  ['coef D_Female', 'se D_Female', 'p-val D_Female']\n",
        "params_dml =  ['coef D_Female', 'se D_Female', 'p-val D_Female']\n",
        "spec_ols = list(reg_user_ols_results.keys() -{'metoo'})\n",
        "spec_dml = list(reg_user_dml_results.keys() - {'metoo(ENet)'} )\n",
        "\n",
        "data_ols = [[reg_user_ols_results[spec][p][0] for p in params_ols] for spec in spec_ols]\n",
        "data_r2 = [[reg_user_ols_results[spec][p] for p in ['R2', 'N Obs']] for spec in spec_ols]\n",
        "data_ols = [data_ols[r] + data_r2[r] for r in range(len(data_ols))]\n",
        "\n",
        "data_dml = [[reg_user_dml_results[spec][p][0] for p in params_dml] for spec in spec_dml]\n",
        "\n",
        "\n",
        "data_DFem = np.asarray(data_ols + data_dml )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "1hXlwwPXW97a"
      },
      "outputs": [],
      "source": [
        "# Cast the reults in tables\n",
        "table_ols_user = pd.DataFrame(np.asarray(data_ols).T, columns= spec_ols,\n",
        "                               index = ['coef', 'SE', 'P-Val', 'R2', 'N'])\n",
        "\n",
        "table_dml_user = pd.DataFrame(np.asarray(data_dml).T, columns= spec_dml,\n",
        "                               index = ['coef', 'SE', 'P-Val'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bKQo7ZtyXpz"
      },
      "source": [
        "## Regression Results Tables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaqppNRevSla"
      },
      "source": [
        "### Without Post×MeToo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "WpmiglfTsvPd"
      },
      "outputs": [],
      "source": [
        "table_results_ols = pd.concat([table_ols_sales, table_ols_budget,\n",
        "                               table_ols_meta, table_ols_user],\n",
        "          axis=0, keys=['sales', 'budget', 'metascore', 'userscore'])\n",
        "\n",
        "table_results_dml = pd.concat([table_dml_sales, table_dml_budget,\n",
        "                               table_dml_meta, table_dml_user],\n",
        "          axis=0, keys=['sales', 'budget' , 'metascore', 'userscore'])\n",
        "\n",
        "table_results_ols.to_csv(results_dir + 'reg_results_ols.csv')\n",
        "table_results_dml.to_csv(results_dir + 'reg_results_dml.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7nMoiqBwCBo"
      },
      "source": [
        "### With Post×MeToo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "Nvpl1YZ6dhxz"
      },
      "outputs": [],
      "source": [
        "data_ols = []\n",
        "data_ols_me2 = []\n",
        "data_r2 = []\n",
        "spec_ols_me2 = ['metoo']\n",
        "ols_results = [reg_sales_ols_results, reg_budget_ols_results, reg_meta_ols_results, \n",
        "               reg_user_ols_results]\n",
        "\n",
        "for result in ols_results:\n",
        "  data_ols = data_ols + [[result[spec][p][0] for p in params_ols] + \n",
        "                [result[spec][p][1] for p in params_ols] \n",
        "                for spec in spec_ols_me2]\n",
        "\n",
        "  data_r2 = data_r2 + [[result[spec][p] for p in ['R2', 'N Obs']] \n",
        "                       for spec in spec_ols_me2]\n",
        "\n",
        "  data_ols_me2 = [data_ols[r] + data_r2[r] for r in range(len(data_ols))]\n",
        "\n",
        "\n",
        "\n",
        "# data_dml_pm2 = [[reg_user_dml_results[spec][p][0] for p in params_dml] +\n",
        "#                 [reg_user_dml_results[spec][p][1] for p in params_dml]\n",
        "#                 for spec in spec_dml_me2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "-Q0V-smFdjdD"
      },
      "outputs": [],
      "source": [
        "data_dml_me2 = []\n",
        "spec_dml_me2 = ['metoo(ENet)']\n",
        "dml_results = [reg_sales_dml_results, reg_budget_dml_results, reg_meta_dml_results, \n",
        "               reg_user_dml_results]\n",
        "\n",
        "for result in dml_results:\n",
        "  data_dml_me2 = data_dml_me2 + [[result[spec][p][0] for p in params_dml] + \n",
        "                [result[spec][p][1] for p in params_dml] \n",
        "                for spec in spec_dml_me2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "dFgp3783kbeR"
      },
      "outputs": [],
      "source": [
        "columns = ['Sales', 'Budget', 'Meta', 'User']\n",
        "index_ols = ['coef', 'SE', 'P-Val', 'coef PMe2', 'SE PMe2', 'P-Val PMe2', 'R2', 'N']\n",
        "index_dml = ['coef', 'SE', 'P-Val', 'coef PMe2', 'SE PMe2', 'P-Val PMe2']\n",
        "\n",
        "\n",
        "table_ols_me2 = pd.DataFrame(np.asarray(data_ols_me2).T, columns= columns,\n",
        "                               index = index_ols)\n",
        "\n",
        "table_dml_me2 = pd.DataFrame(np.asarray(data_dml_me2).T, columns= columns,\n",
        "                               index = index_dml)\n",
        "\n",
        "table_ols_me2.to_csv(results_dir + 'reg_results_me2_ols.csv')\n",
        "table_dml_me2.to_csv(results_dir + 'reg_results_me2_dml.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "WdEO3iHF33hW",
        "I7Xdq-4Thnt9",
        "wfAXjnXYh5NE"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNADQrKy0dr2O/jSEYi3lJ8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}